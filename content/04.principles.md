
## Principles of Context-Adaptive Inference
What makes a model adaptive? When is it good for a model to be adaptive? While the appeal of adaptivity lies in flexibility and personalized inference, not all adaptivity is good adaptivity. In this section, we formalize the core principles that underlie adaptive modeling.

### 1. Adaptivity requires flexibility
A model cannot adapt unless it has the capacity to represent multiple behaviors. Flexibility may take the form of nonlinearity, hierarchical structure, or modular components that allow different responses in different settings.

- Interaction effects in regression models [@doi:10.1145/2783258.2788613]
- Hierarchical models that allow for varying effects across groups
- Meta-learning and mixtures-of-experts models that learn to adapt based on context
- Varying-coefficient models that allow coefficients to change with context [@doi:10.1111/j.2517-6161.1993.tb01939.x]

### 2. Adaptivity requires a signal of heterogeneity
- Varying-coefficient models adapt parameters based on observed context [@doi:10.1111/j.2517-6161.1993.tb01939.x]
- Contextual bandits adapt actions to context features [@arxiv:1811.04383]
- Multi-domain models adapt across known environments or inferred partitions [@arXiv:2010.07249]

### 3. Modularity improves adaptivity
Adaptive systems are easier to design, debug, and interpret when built from modular parts. Modularity supports targeted adaptation, transferability, and disentanglement.

- []

### 4. Adaptivity implies selectivity
Adaptation must be earned. Overreacting to limited data leads to overfitting. The best adaptive methods include mechanisms for deciding when not to adapt.
- Lepski's method [@arxiv:1508.00249]
- Aggregation of classifiers [@doi:10.1007/978-3-540-45167-9_23]

### 5. Adaptivity is bounded by data efficiency
[@arxiv:1911.12568]

### 6. Adaptivity is not a free lunch

Adaptivity improves performance when heterogeneity is real and informative, but it can degrade performance when variation is spurious. Key tradeoffs include:

- **Bias vs. variance**: More flexible adaptation can reduce bias but increase variance
- **Stability vs. personalization**: Highly adaptive models may overfit to noise or adversarial context
- **Inference cost**: Adaptive inference may be more computationally intensive than global prediction

Understanding these tradeoffs is essential when designing systems for real-world deployment.


### When Adaptivity Fails: Common Failure Modes
Even when all the ingredients are present, adaptivity can backfire. Common failure modes include:

- Spurious Adaptation: Adapting to unstable or confounded features [@arXiv:2010.05761]
- Overfitting in Low-Data Contexts: Attempting fine-grained adaptation with insufficient signal
- Modularity Mis-specification: Adapting in the wrong units or groupings [@arXiv:1911.08731]
- Feedback Loops: Models that change the data distribution they rely on [@doi:10.1145/3097983.3098066]



Related references:


