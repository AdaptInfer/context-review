## Opportunities for Foundation Models

### Expanding Frameworks
TODO: Define foundation models, Explore how foundation models are redefining possibilities within statistical models.


### Foundation models as context
TODO: Show recent progress and ongoing directions in using foundation models as context.
The work "LMPriors: Pre-Trained Language Models as Task-Specific Priors [@doi:10.48550/arXiv.2210.12530] presents a novel method emphasizing on leveraging Language Model Priors with task relevant knowledge to enhance machine learning performance.Its basic concept is to guide downstream activities including feature selection, causal discovery and reinforcement learning using task relevant knowledge from foundation models (here GPT-3 is employed).Without requiring a lot of data or overfitting, LMPriors produce better educated decisions by using job relevant information including variable and their description curated with machine learning algorithm.This work suggested approach for using rich and contextual knowledge of large language models into the machine learning process decision making.The current machine learning models applied shrinkage or sparsity, which is not practical for task specific reasoning.LMPriors raises benchmarks for reinforcement learning, causal discovery, and feature selection.It outperforms LassoNet in causal direction inference by using fewer but more semantically significant attributes to boost causal discovery accuracy to 88.7%. LMPriors improve reinforcement learning safety and performance by integrating past information in reward shaping, leading agents toward better and safer choices.However,The LMPrior structure has limitation that  requires well-written prompts. Poorly crafted or biased questions may involve preconceptions. LMPriors use language models, with possibly having pre-trained model biases. Therefore,choosing input data and prompts carefully  must be carefully handled in order to extract best outputs . Biased reinforcement learning priors can generate unsafe or poor behavior. Even though LMPriors have great potential, they must be strictly controlled to ensure fairness and avoid ethical issues.




With the advancement of foundation models, the FLAN-MoE (fine-tuned language model with mixture of experts) architectures [@doi:10.48550/arXiv.2305.14705] represent a novel approach to these existing models, including efficiency involved with contextualised modeling. It combines instruction tuning and sparse mix of experts (MoE) which ensures combining larger domains of NLP tasks, reducing computational overhead, and ensuring efficient contextualisation concurrently. It ensures contextualisation by selecting specialised experts on the basis of the provided input by a dynamic gating mechanism. Instruction tuning further makes the capability even in broader aspects implementing few-shot and zero-shot generalization. It shows an improvement in result over the fully dense state-of-the-art models. Combining foundation models’ transfer capabilities. Fine-grained control in task execution can be ensured along with contextual routing and expert activation of MoE architectures. It ensures handling of broad instructions with pre-trained knowledge and concurrently adapts to the sub-tasks of a specific task with expert selection.Moreover, FLAN-MoE can be interpreted as an application in post-hoc interpretability. Since different experts are assigned with particular tasks while providing particular output,. It gives insights for interpretability into the decision-making process of the model. To summarise, FLAN-MoE addresses the challenges of scaling, efficiency, and generalisation across a wider range of tasks by combining the idea of a sparse mixture of expert selection models and instruction tuning. The possible extension to it may involve more sophisticated gating mechanisms, multilingual instruction-tuning, and more to be explored.


Consequently, along with all the existing foundation models, the Mixture of In-Context Experts (MoICE) [@doi:10.48550/arXiv.2210.12530] is one of the recent studies that address the challenges of understanding long contexts, dynamic routing, and efficient task-specific contextualization. Incorporating a dynamic routing mechanism and multiple Rotary Position Embeddings (RoPE) angles, MoICE enhances the attention mechanism of large language models (LLMs).  RoPE encodes the positional information of the token embeddings.This resolves the problem of the inability to ensure the order of tokens, which is one of the major drawbacks of the standard attention mechanism. RoPE angles are parameters in the rotary embedding that determine the rotation amount of the token's embeddings to encode its positional information.MoICE introduces in-context experts, where a dynamic router mechanism is integrated into each attention head, allowing token-wise adaptability. Here, the most relevant RoPE angles are assigned dynamically to each token in the sequence, ensuring that no information, whether it is at the start, middle, or end, is missed. Attention heads select the RoPE angles according to their role, which ensures adaptability to varying contexts of the model. Thus, dynamic routing with in-context experts is implemented. Moreover, MoICE contributes to the efficient contextualization of foundation models by router-only training and minimized memory usage.  It trains only the routers, freezing the base LLM parameters, rather than training the whole model parameters.During expert activation,  MoICE chooses a subset of RoPE angles ensuring the minimization of memory overhead. It reveals how attention is distributed across different parts of the input sequence which demonstrates its interpretability and decision making capability .Dynamically selected RoPE angle provides insights into the relative importance of different contextual positions of the tokens It offers transparency in the model’s reasoning process, which is ensured in the prioritization of tokens during the generation step. MoICE demonstrates significant performance improvements across tasks requiring long-context understanding and retrieval-augmented generation (RAG) in the context of both open-ended and closed-ended tasks. In a nutshell, MoICE stands out as being efficient architecture built on the principles of foundation models, which consists of the capability to dynamically adjust to varying contexts. With its lightweight training approach, it has evolved into a more sophisticated tool, especially for the interpretability of long-context tasks.
