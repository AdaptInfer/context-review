
## Context-Invariant Training: A View from the Converse
TODO: The converse of context-adaptive models, exploring the implications of training context-invariant models.
e.g. out-of-distribution generalization, robustness to adversarial attacks. test test

Relevant references:

- Invariant Risk Minimization [@arXiv:1907.02893]
- Out-of-Distribution Generalization via Risk Extrapolation [@arXiv:2003.00688]
- The Risks of Invariant Risk Minimization [@arXiv:2010.05761]
- Conditional Variance Penalties and Domain Adaptation [@arXiv:1710.11469]
- Can Subpopulation Shifts Explain Disagreement in Model Generalization? [@arXiv:2106.04486]

### Adversarial Robustness as Context-Invariant Training
Related references:

- Towards Deep Learning Models Resistant to Adversarial Attacks [@arXiv:1706.06083]
- Robustness May Be at Odds with Accuracy [@arXiv:1805.12152]

### Training methods for Context-Invariant Models
- Just Train Twice: Improving Group Robustness without Training Group Information [@arXiv:2002.10384]
- Environment Inference for Invariant Learning [@arXiv:2110.14048]
- Distributionally Robust Neural Networks for Group Shifts [@arXiv:1911.08731]

