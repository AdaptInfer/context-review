[
  {
    "id": "1CkxORTSX",
    "URL": "https://arxiv.org/abs/2103.00315",
    "number": "2103.00315",
    "title": "Time-Varying Coefficient Model Estimation Through Radial Basis Functions",
    "issued": {
      "date-parts": [
        [
          2021,
          3,
          2
        ]
      ]
    },
    "author": [
      {
        "given": "Juan",
        "family": "Sosa"
      },
      {
        "given": "Lina",
        "family": "Buitrago"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "In this paper we estimate the dynamic parameters of a time-varying coefficient model through radial kernel functions in the context of a longitudinal study. Our proposal is based on a linear combination of weighted kernel functions involving a bandwidth, centered around a given set of time points. In addition, we study different alternatives of estimation and inference including a Frequentist approach using weighted least squares along with bootstrap methods, and a Bayesian approach through both Markov chain Monte Carlo and variational methods. We compare the estimation strategies mention above with each other, and our radial kernel functions proposal with an expansion based on regression spline, by means of an extensive simulation study considering multiples scenarios in terms of sample size, number of repeated measurements, and subject-specific correlation. Our experiments show that the capabilities of our proposal based on radial kernel functions are indeed comparable with or even better than those obtained from regression splines. We illustrate our methodology by analyzing data from two AIDS clinical studies.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2103.00315"
  },
  {
    "publisher": "Elsevier BV",
    "DOI": "10.1016/j.jbi.2022.104086",
    "type": "article-journal",
    "page": "104086",
    "source": "Crossref",
    "title": "Automated interpretable discovery of heterogeneous treatment effectiveness: A COVID-19 case study",
    "volume": "130",
    "author": [
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Mark E.",
        "family": "Nunnally"
      },
      {
        "given": "Yin",
        "family": "Aphinyanaphongs"
      },
      {
        "given": "Caleb",
        "family": "Ellington"
      },
      {
        "given": "Rich",
        "family": "Caruana"
      }
    ],
    "container-title": "Journal of Biomedical Informatics",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          6
        ]
      ]
    },
    "URL": "https://doi.org/gt68h5",
    "container-title-short": "Journal of Biomedical Informatics",
    "PMCID": "PMC9055753",
    "PMID": "35504543",
    "id": "esxxcr9l",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1016/j.jbi.2022.104086"
  },
  {
    "publisher": "Informa UK Limited",
    "issue": "538",
    "DOI": "10.1080/01621459.2021.2000866",
    "type": "article-journal",
    "page": "533-546",
    "source": "Crossref",
    "title": "Bayesian Edge Regression in Undirected Graphical Models to Characterize Interpatient Heterogeneity in Cancer",
    "volume": "117",
    "author": [
      {
        "given": "Zeya",
        "family": "Wang"
      },
      {
        "given": "Veerabhadran",
        "family": "Baladandayuthapani"
      },
      {
        "given": "Ahmed O.",
        "family": "Kaseb"
      },
      {
        "given": "Hesham M.",
        "family": "Amin"
      },
      {
        "given": "Manal M.",
        "family": "Hassan"
      },
      {
        "given": "Wenyi",
        "family": "Wang"
      },
      {
        "given": "Jeffrey S.",
        "family": "Morris"
      }
    ],
    "container-title": "Journal of the American Statistical Association",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          1,
          5
        ]
      ]
    },
    "URL": "https://doi.org/gt68hr",
    "container-title-short": "Journal of the American Statistical Association",
    "PMCID": "PMC9454401",
    "PMID": "36090952",
    "id": "TULLRYDp",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1080/01621459.2021.2000866"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Summarizing multiple data modalities into a parsimonious cancer “subtype” is difficult because the most informative representation of each patient’s disease is not observed. We propose to model these latent summaries as<jats:italic>discriminative subtypes</jats:italic>: sample representations which induce accurate and interpretable sample-specific models for downstream predictions. In this way, discriminative subtypes, which are shared between data modalities, can be estimated from one data modality and optimized according to the predictions induced in another modality. We apply this approach to lung cancer by training a deep neural network to predict discriminative subtypes from histopathology images, and use these predicted subtypes to generate models which classify adenocarcinoma, squamous cell carcinoma, and healthy tissue based on transcriptomic signatures. In this way, we optimize the latent discriminative subtypes through induced prediction loss, and the discriminative subtypes are interpreted with standard interpretation of transcriptomic predictive models. Our framework achieves state-of-the-art classification accuracy (F1-score of 0.97) and identifies discriminative subtypes which link histopathology images to transcriptomic explanations without requiring pre-specification of morphological patterns or transcriptomic processes.</jats:p>",
    "DOI": "10.1101/2020.06.25.20140053",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Discriminative Subtyping of Lung Cancers from Histopathology Images via Contextual Deep Learning",
    "author": [
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Maruan",
        "family": "Al-Shedivat"
      },
      {
        "given": "Amir",
        "family": "Alavi"
      },
      {
        "given": "Jennifer",
        "family": "Williams"
      },
      {
        "given": "Sami",
        "family": "Labbaki"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020,
          6,
          26
        ]
      ]
    },
    "URL": "https://doi.org/gt68h6",
    "id": "O1UU4a5P",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2020.06.25.20140053"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:p>Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory networks (GRNs) from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond coarse analyses of pre-defined subgroups by using<jats:italic>contextualized</jats:italic>learning, a multi-task learning paradigm that uses multi-view contexts including phenotypic, molecular, and environmental information to infer personalized models. With sample-specific contexts, contextualization enables sample-specific models and even generalizes at test time to predict network models for entirely unseen contexts. We unify three network model classes (Correlation, Markov, Neighborhood Selection) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, using copy number and driver mutation profiles, tumor microenvironment, and patient demographics as model context. Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology by providing a structured view of expression dynamics at sample-specific resolution, explaining known biomarkers in terms of network-mediated effects and leading to novel subtypings that improve survival prognosis. We provide a SKLearn-style Python package<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://contextualized.ml\">https://contextualized.ml</jats:ext-link>for learning and analyzing contextualized models, as well as interactive plotting tools for pan-cancer data exploration at<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/cnellington/CancerContextualized\">https://github.com/cnellington/CancerContextualized</jats:ext-link>.</jats:p><jats:sec><jats:title>Significance Statement</jats:title><jats:p>Network estimation is essential for understanding the structure and function of biological systems, but current statistical approaches fail to capture inter-subject heterogeneity or cross-modality information flow, both of which are needed for understanding complex phenotypes and pathologies. We introduce contextualized network inference, leveraging multi-view contextual metadata to capture similarities and differences among heterogeneous observations during network estimation. Sharing information across contexts enables inference at sample-specific resolution, thus quantifying variation between subjects and revealing context-specific network rewiring. Applied to tumor-specific transcriptional network inference using clinical, molecular, and multi-omic data, contextualized networks improve accuracy, generalize to unseen cancer types, and discover novel prognostic tumor subtypes. By tailoring disease models to each sample, contextualized networks promise to enable precision medicine at unprecedented resolution.</jats:p></jats:sec>",
    "DOI": "10.1101/2023.12.01.569658",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Learning to Estimate Sample-specific Transcriptional Networks for 7000 Tumors",
    "author": [
      {
        "given": "Caleb N.",
        "family": "Ellington"
      },
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Thomas B.K.",
        "family": "Watkins"
      },
      {
        "given": "Jiekun",
        "family": "Yang"
      },
      {
        "given": "Abhinav",
        "family": "Adduri"
      },
      {
        "given": "Sazan",
        "family": "Mahbub"
      },
      {
        "given": "Hanxi",
        "family": "Xiao"
      },
      {
        "given": "Manolis",
        "family": "Kellis"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          12,
          4
        ]
      ]
    },
    "URL": "https://doi.org/gt68h7",
    "id": "Rt6voTFN",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.12.01.569658"
  },
  {
    "publisher": "Oxford University Press (OUP)",
    "issue": "4",
    "abstract": "<jats:title>SUMMARY</jats:title>\n               <jats:p>We explore a class of regression and generalized regression models in which the coefficients are allowed to vary as smooth functions of other variables. General algorithms are presented for estimating the models flexibly and some examples are given. This class of models ties together generalized additive models and dynamic generalized linear models into one common framework. When applied to the proportional hazards model for survival data, this approach provides a new way of modelling departures from the proportional hazards assumption.</jats:p>",
    "DOI": "10.1111/j.2517-6161.1993.tb01939.x",
    "type": "article-journal",
    "page": "757-779",
    "source": "Crossref",
    "title": "Varying-Coefficient Models",
    "volume": "55",
    "author": [
      {
        "given": "Trevor",
        "family": "Hastie"
      },
      {
        "given": "Robert",
        "family": "Tibshirani"
      }
    ],
    "container-title": "Journal of the Royal Statistical Society Series B: Statistical Methodology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          1993,
          9,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gmfvmb",
    "id": "ugXwusl0",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1111/j.2517-6161.1993.tb01939.x"
  },
  {
    "publisher": "Institute of Mathematical Statistics",
    "issue": "1",
    "DOI": "10.1214/09-aoas308",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Estimating time-varying networks",
    "volume": "4",
    "author": [
      {
        "given": "Mladen",
        "family": "Kolar"
      },
      {
        "given": "Le",
        "family": "Song"
      },
      {
        "given": "Amr",
        "family": "Ahmed"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "container-title": "The Annals of Applied Statistics",
    "issued": {
      "date-parts": [
        [
          2010,
          3,
          1
        ]
      ]
    },
    "URL": "https://doi.org/b3rn6q",
    "container-title-short": "Ann. Appl. Stat.",
    "id": "lAsTg3IH",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1214/09-aoas308"
  },
  {
    "publisher": "Institute of Mathematical Statistics",
    "issue": "5",
    "DOI": "10.1214/aos/1017939139",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Statistical estimation in varying coefficient models",
    "volume": "27",
    "author": [
      {
        "given": "Jianqing",
        "family": "Fan"
      },
      {
        "given": "Wenyang",
        "family": "Zhang"
      }
    ],
    "container-title": "The Annals of Statistics",
    "issued": {
      "date-parts": [
        [
          1999,
          10,
          1
        ]
      ]
    },
    "URL": "https://doi.org/dsxd4s",
    "container-title-short": "Ann. Statist.",
    "id": "l6vMkIsa",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1214/aos/1017939139"
  },
  {
    "publisher": "The Open Journal",
    "issue": "97",
    "DOI": "10.21105/joss.06469",
    "type": "article-journal",
    "page": "6469",
    "source": "Crossref",
    "title": "Contextualized: Heterogeneous Modeling Toolbox",
    "volume": "9",
    "author": [
      {
        "given": "Caleb N.",
        "family": "Ellington"
      },
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Wesley",
        "family": "Lo"
      },
      {
        "given": "Aaron",
        "family": "Alvarez"
      },
      {
        "given": "Andrea",
        "family": "Rubbi"
      },
      {
        "given": "Manolis",
        "family": "Kellis"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "container-title": "Journal of Open Source Software",
    "issued": {
      "date-parts": [
        [
          2024,
          5,
          8
        ]
      ]
    },
    "URL": "https://doi.org/gt68h8",
    "container-title-short": "JOSS",
    "id": "4cK1tiec",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.21105/joss.06469"
  },
  {
    "type": "article",
    "id": "SfCo6pSp",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Al-Shedivat",
        "given": "Maruan"
      },
      {
        "family": "Dubey",
        "given": "Avinava"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "abstract": "Modern learning algorithms excel at producing accurate but complex models of the data. However, deploying such models in the real-world requires extra care: we must ensure their reliability, robustness, and absence of undesired biases. This motivates the development of models that are equally accurate but can be also easily inspected and assessed beyond their predictive performance. To this end, we introduce contextual explanation networks (CEN)---a class of architectures that learn to predict by generating and utilizing intermediate, simplified probabilistic models. Specifically, CENs generate parameters for intermediate graphical models which are further used for prediction and play the role of explanations. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain simultaneously. Our approach offers two major advantages: (i) for each prediction valid, instance-specific explanation is generated with no computational overhead and (ii) prediction via explanation acts as a regularizer and boosts performance in data-scarce settings. We analyze the proposed framework theoretically and experimentally. Our results on image and text classification and survival analysis tasks demonstrate that CENs are not only competitive with the state-of-the-art methods but also offer additional insights behind each prediction, that can be valuable for decision support. We also show that while post-hoc methods may produce misleading explanations in certain cases, CENs are consistent and allow to detect such cases systematically.",
    "DOI": "10.48550/arxiv.1705.10301",
    "publisher": "arXiv",
    "title": "Contextual Explanation Networks",
    "URL": "https://doi.org/gt68h9",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1705.10301"
  },
  {
    "type": "article",
    "id": "1CmXccjU0",
    "categories": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Arjovsky",
        "given": "Martin"
      },
      {
        "family": "Bottou",
        "given": "Léon"
      },
      {
        "family": "Gulrajani",
        "given": "Ishaan"
      },
      {
        "family": "Lopez-Paz",
        "given": "David"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "abstract": "We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.",
    "DOI": "10.48550/arxiv.1907.02893",
    "publisher": "arXiv",
    "title": "Invariant Risk Minimization",
    "URL": "https://doi.org/gz355c",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1907.02893"
  },
  {
    "type": "article",
    "id": "WlwUpYp",
    "categories": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Benjamin"
      },
      {
        "family": "Aragam",
        "given": "Bryon"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "abstract": "Modern applications of machine learning (ML) deal with increasingly heterogeneous datasets comprised of data collected from overlapping latent subpopulations. As a result, traditional models trained over large datasets may fail to recognize highly predictive localized effects in favour of weakly predictive global patterns. This is a problem because localized effects are critical to developing individualized policies and treatment plans in applications ranging from precision medicine to advertising. To address this challenge, we propose to estimate sample-specific models that tailor inference and prediction at the individual level. In contrast to classical ML models that estimate a single, complex model (or only a few complex models), our approach produces a model personalized to each sample. These sample-specific models can be studied to understand subgroup dynamics that go beyond coarse-grained class labels. Crucially, our approach does not assume that relationships between samples (e.g. a similarity network) are known a priori. Instead, we use unmodeled covariates to learn a latent distance metric over the samples. We apply this approach to financial, biomedical, and electoral data as well as simulated data and show that sample-specific models provide fine-grained interpretations of complicated phenomena without sacrificing predictive accuracy compared to state-of-the-art models such as deep neural networks.",
    "DOI": "10.48550/arxiv.1910.06939",
    "publisher": "arXiv",
    "title": "Learning Sample-Specific Models with Low-Rank Personalized Regression",
    "URL": "https://doi.org/gt68jb",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1910.06939"
  },
  {
    "type": "article",
    "id": "grNza1Og",
    "categories": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Ben"
      },
      {
        "family": "Ellington",
        "given": "Caleb"
      },
      {
        "family": "Aragam",
        "given": "Bryon"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      },
      {
        "family": "Kellis",
        "given": "Manolis"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs) identify context-dependent relationships between variables, but the non-convexity induced by the acyclicity requirement makes it difficult to share information between context-specific estimators (e.g. with graph generator functions). For this reason, existing methods for inferring context-specific Bayesian networks have favored breaking datasets into subsamples, limiting statistical power and resolution, and preventing the use of multidimensional and latent contexts. To overcome this challenge, we propose NOTEARS-optimized Mixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian networks as the output of a function which learns to mix archetypal networks according to sample context. The archetypal networks are estimated jointly with the context-specific networks and do not require any prior knowledge. We encode the acyclicity constraint as a smooth regularization loss which is back-propagated to the mixing function; in this way, NOTMAD shares information between context-specific acyclic graphs, enabling the estimation of Bayesian network structures and parameters at even single-sample resolution. We demonstrate the utility of NOTMAD and sample-specific network inference through analysis and experiments, including patient-specific gene expression networks which correspond to morphological variation in cancer.",
    "DOI": "10.48550/arxiv.2111.01104",
    "publisher": "arXiv",
    "title": "NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and Parameters",
    "URL": "https://doi.org/gt68jc",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2111.01104"
  },
  {
    "type": "article",
    "id": "k6r0UwSv",
    "categories": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Suriyakumar",
        "given": "Vinith M."
      },
      {
        "family": "Ghassemi",
        "given": "Marzyeh"
      },
      {
        "family": "Ustun",
        "given": "Berk"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "Machine learning models are often personalized with categorical attributes that are protected, sensitive, self-reported, or costly to acquire. In this work, we show models that are personalized with group attributes can reduce performance at a group level. We propose formal conditions to ensure the \"fair use\" of group attributes in prediction tasks by training one additional model -- i.e., collective preference guarantees to ensure that each group who provides personal data will receive a tailored gain in performance in return. We present sufficient conditions to ensure fair use in empirical risk minimization and characterize failure modes that lead to fair use violations due to standard practices in model development and deployment. We present a comprehensive empirical study of fair use in clinical prediction tasks. Our results demonstrate the prevalence of fair use violations in practice and illustrate simple interventions to mitigate their harm.",
    "DOI": "10.48550/arxiv.2206.02058",
    "publisher": "arXiv",
    "title": "When Personalization Harms: Reconsidering the Use of Group Attributes in Prediction",
    "URL": "https://doi.org/gt68jd",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2206.02058"
  },
  {
    "type": "article",
    "id": "nYipTPML",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Deuschel",
        "given": "Jannik"
      },
      {
        "family": "Ellington",
        "given": "Caleb N."
      },
      {
        "family": "Luo",
        "given": "Yingtao"
      },
      {
        "family": "Lengerich",
        "given": "Benjamin J."
      },
      {
        "family": "Friederich",
        "given": "Pascal"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models force a tradeoff between accuracy and interpretability, limiting data-driven interpretations of human decision-making processes. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically under different contexts. Thus, we develop Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem, where each context poses a unique task and complex decision policies can be constructed piece-wise from many simple context-specific policies. CPR models each context-specific policy as a linear map, and generates new policy models $\\textit{on-demand}$ as contexts are updated with new observations. We provide two flavors of the CPR framework: one focusing on exact local interpretability, and one retaining full global interpretability. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement, CPR closes the accuracy gap between interpretable and black-box methods, allowing high-resolution exploration and analysis of context-specific decision models.",
    "DOI": "10.48550/arxiv.2310.07918",
    "publisher": "arXiv",
    "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning",
    "URL": "https://doi.org/gt68jf",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2310.07918"
  },
  {
    "type": "article",
    "id": "HYsEq2UQ",
    "categories": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Benjamin"
      },
      {
        "family": "Ellington",
        "given": "Caleb N."
      },
      {
        "family": "Rubbi",
        "given": "Andrea"
      },
      {
        "family": "Kellis",
        "given": "Manolis"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "We examine Contextualized Machine Learning (ML), a paradigm for learning heterogeneous and context-dependent effects. Contextualized ML estimates heterogeneous functions by applying deep learning to the meta-relationship between contextual information and context-specific parametric models. This is a form of varying-coefficient modeling that unifies existing frameworks including cluster analysis and cohort modeling by introducing two reusable concepts: a context encoder which translates sample context into model parameters, and sample-specific model which operates on sample predictors. We review the process of developing contextualized models, nonparametric inference from contextualized models, and identifiability conditions of contextualized models. Finally, we present the open-source PyTorch package ContextualizedML.",
    "DOI": "10.48550/arxiv.2310.11340",
    "publisher": "arXiv",
    "title": "Contextualized Machine Learning",
    "URL": "https://doi.org/gt68jg",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2310.11340"
  },
  {
    "type": "article",
    "id": "9S6tI5yv",
    "categories": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Sristi",
        "given": "Ram Dyuthi"
      },
      {
        "family": "Lindenbaum",
        "given": "Ofir"
      },
      {
        "family": "Lifshitz",
        "given": "Shira"
      },
      {
        "family": "Lavzin",
        "given": "Maria"
      },
      {
        "family": "Schiller",
        "given": "Jackie"
      },
      {
        "family": "Mishne",
        "given": "Gal"
      },
      {
        "family": "Benisty",
        "given": "Hadas"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Feature selection is a crucial tool in machine learning and is widely applied across various scientific disciplines. Traditional supervised methods generally identify a universal set of informative features for the entire population. However, feature relevance often varies with context, while the context itself may not directly affect the outcome variable. Here, we propose a novel architecture for contextual feature selection where the subset of selected features is conditioned on the value of context variables. Our new approach, Conditional Stochastic Gates (c-STG), models the importance of features using conditional Bernoulli variables whose parameters are predicted based on contextual variables. We introduce a hypernetwork that maps context variables to feature selection parameters to learn the context-dependent gates along with a prediction model. We further present a theoretical analysis of our model, indicating that it can improve performance and flexibility over population-level methods in complex feature selection settings. Finally, we conduct an extensive benchmark using simulated and real-world datasets across multiple domains demonstrating that c-STG can lead to improved feature selection capabilities while enhancing prediction accuracy and interpretability.",
    "DOI": "10.48550/arxiv.2312.14254",
    "publisher": "arXiv",
    "title": "Contextual Feature Selection with Conditional Stochastic Gates",
    "URL": "https://doi.org/gt68jh",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2312.14254"
  }
]
