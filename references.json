[
  {
    "id": "bnBshyMZ",
    "type": "manuscript",
    "author": [
      {
        "family": "Alain",
        "given": "Guillaume"
      },
      {
        "family": "Bengio",
        "given": "Yoshua"
      }
    ],
    "title": "Understanding Intermediate Layers Using Linear Classifier Probes",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: AlainBengio2016"
  },
  {
    "id": "10jCLvzty",
    "type": "paper-conference",
    "author": [
      {
        "family": "Alemi",
        "given": "Alexander A."
      },
      {
        "family": "Fischer",
        "given": "Ian"
      },
      {
        "family": "Dillon",
        "given": "Joshua V."
      },
      {
        "family": "Murphy",
        "given": "Kevin"
      }
    ],
    "title": "Deep Variational Information Bottleneck",
    "container-title": "International Conference on Learning Representations",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: AlemiFischerDillonMurphy2017"
  },
  {
    "id": "19AZg3mLf",
    "type": "manuscript",
    "author": [
      {
        "family": "Bordt",
        "given": "Sebastian"
      },
      {
        "family": "Raidl",
        "given": "Eric"
      },
      {
        "family": "von Luxburg",
        "given": "Ulrike"
      }
    ],
    "title": "Rethinking Explainable Machine Learning as Applied Statistics",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: BordtRaidlLuxburg2024"
  },
  {
    "id": "quy0xhhL",
    "type": "paper-conference",
    "author": [
      {
        "family": "Chen",
        "given": "Chaofan"
      },
      {
        "family": "Li",
        "given": "Oscar"
      },
      {
        "family": "Tao",
        "given": "Daniel"
      },
      {
        "family": "Barnett",
        "given": "Alina"
      },
      {
        "family": "Su",
        "given": "Jonathan"
      },
      {
        "family": "Rudin",
        "given": "Cynthia"
      }
    ],
    "title": "This Looks Like That: Deep Learning for Interpretable Image Recognition",
    "container-title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
    "DOI": "10.1109/CVPR.2019.00914",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: ChenLiTaoBarnettSuRudin2019"
  },
  {
    "id": "B1j4YBEB",
    "type": "paper-conference",
    "author": [
      {
        "family": "Cremer",
        "given": "Chris"
      },
      {
        "family": "Morris",
        "given": "Quaid"
      },
      {
        "family": "Duvenaud",
        "given": "David"
      }
    ],
    "title": "Inference Suboptimality in Variational Autoencoders",
    "container-title": "Proceedings of the 35th International Conference on Machine Learning",
    "publisher": "PMLR",
    "volume": "80",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: CremerMorrisDuvenaud2018"
  },
  {
    "id": "xdOmjxko",
    "type": "paper-conference",
    "author": [
      {
        "family": "Koh",
        "given": "Pang Wei"
      },
      {
        "family": "Liang",
        "given": "Percy"
      }
    ],
    "title": "Understanding Black-box Predictions via Influence Functions",
    "container-title": "Proceedings of the 34th International Conference on Machine Learning",
    "publisher": "PMLR",
    "volume": "70",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: KohLiang2017"
  },
  {
    "id": "KboFKxwb",
    "type": "manuscript",
    "author": [
      {
        "family": "Kroeger",
        "given": "Nicholas"
      },
      {
        "family": "Ley",
        "given": "Dan"
      },
      {
        "family": "Krishna",
        "given": "Satyapriya"
      },
      {
        "family": "Agarwal",
        "given": "Chirag"
      },
      {
        "family": "Lakkaraju",
        "given": "Himabindu"
      }
    ],
    "title": "In-Context Explainers: Harnessing LLMs for Explaining Black Box Models",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: KroegerLeyKrishnaAgarwalLakkaraju2024"
  },
  {
    "id": "StZxZNd2",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lundberg",
        "given": "Scott M."
      },
      {
        "family": "Lee",
        "given": "Su-In"
      }
    ],
    "title": "A Unified Approach to Interpreting Model Predictions",
    "container-title": "Advances in Neural Information Processing Systems",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: LundbergLee2017"
  },
  {
    "id": "e9kuC7bS",
    "type": "paper-conference",
    "author": [
      {
        "family": "Meng",
        "given": "Kevin"
      },
      {
        "family": "Bau",
        "given": "David"
      },
      {
        "family": "Andonian",
        "given": "Alex"
      },
      {
        "family": "Belinkov",
        "given": "Yonatan"
      }
    ],
    "title": "Locating and Editing Factual Associations in GPT",
    "container-title": "Advances in Neural Information Processing Systems",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: MengBauAndonianBelinkov2022"
  },
  {
    "id": "1GR6qhy9S",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ribeiro",
        "given": "Marco Tulio"
      },
      {
        "family": "Singh",
        "given": "Sameer"
      },
      {
        "family": "Guestrin",
        "given": "Carlos"
      }
    ],
    "title": "“Why Should I Trust You?”: Explaining the Predictions of Any Classifier",
    "container-title": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
    "publisher": "ACM",
    "DOI": "10.1145/2939672.2939778",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: RibeiroSinghGuestrin2016"
  },
  {
    "id": "F5p7aZaa",
    "type": "manuscript",
    "author": [
      {
        "family": "Shrikumar",
        "given": "Avanti"
      },
      {
        "family": "Greenside",
        "given": "Peyton"
      },
      {
        "family": "Kundaje",
        "given": "Anshul"
      }
    ],
    "title": "Learning Important Features Through Propagating Activation Differences",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: ShrikumarGreensideKundaje2017"
  },
  {
    "id": "rMp9yyDJ",
    "type": "paper-conference",
    "author": [
      {
        "family": "Sundararajan",
        "given": "Mukund"
      },
      {
        "family": "Taly",
        "given": "Ankur"
      },
      {
        "family": "Yan",
        "given": "Qiqi"
      }
    ],
    "title": "Axiomatic Attribution for Deep Networks",
    "container-title": "Proceedings of the 34th International Conference on Machine Learning",
    "publisher": "PMLR",
    "volume": "70",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: SundararajanTalyYan2017"
  },
  {
    "id": "12TaD6gil",
    "type": "paper-conference",
    "author": [
      {
        "family": "Tenney",
        "given": "Ian"
      },
      {
        "family": "Xia",
        "given": "Patrick"
      },
      {
        "family": "Chen",
        "given": "Berlin"
      }
    ],
    "title": "What Do You Learn from Context? Probing for Sentence Structure in Contextualized Word Representations",
    "container-title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT)",
    "publisher": "Association for Computational Linguistics",
    "note": "and other authors\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: TenneyDasPavlick2019"
  },
  {
    "id": "1GChRhAEq",
    "type": "article-journal",
    "author": [
      {
        "family": "Ang",
        "given": "Andrew"
      },
      {
        "family": "Bekaert",
        "given": "Geert"
      }
    ],
    "title": "Asset Allocation with Regime Shifts and Long-Horizon Risks",
    "container-title": "Review of Financial Studies",
    "volume": "27",
    "issue": "12",
    "page": "3734--3777",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: ang2014asset"
  },
  {
    "id": "wK1jbWkS",
    "URL": "https://arxiv.org/abs/1508.00249",
    "number": "1508.00249",
    "title": "Lepski's Method and Adaptive Estimation of Nonlinear Integral Functionals of Density",
    "issued": {
      "date-parts": [
        [
          2016,
          1,
          12
        ]
      ]
    },
    "author": [
      {
        "given": "Rajarshi",
        "family": "Mukherjee"
      },
      {
        "given": "Eric Tchetgen",
        "family": "Tchetgen"
      },
      {
        "given": "James",
        "family": "Robins"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "We study the adaptive minimax estimation of non-linear integral functionals of a density and extend the results obtained for linear and quadratic functionals to general functionals. The typical rate optimal non-adaptive minimax estimators of \"smooth\" non-linear functionals are higher order U-statistics. Since Lepski's method requires tight control of tails of such estimators, we bypass such calculations by a modification of Lepski's method which is applicable in such situations. As a necessary ingredient, we also provide a method to control higher order moments of minimax estimator of cubic integral functionals. Following a standard constrained risk inequality method, we also show the optimality of our adaptation rates.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1508.00249"
  },
  {
    "id": "B0L8KJ8W",
    "URL": "https://arxiv.org/abs/1706.06083",
    "number": "1706.06083",
    "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
    "issued": {
      "date-parts": [
        [
          2019,
          9,
          6
        ]
      ]
    },
    "author": [
      {
        "given": "Aleksander",
        "family": "Madry"
      },
      {
        "given": "Aleksandar",
        "family": "Makelov"
      },
      {
        "given": "Ludwig",
        "family": "Schmidt"
      },
      {
        "given": "Dimitris",
        "family": "Tsipras"
      },
      {
        "given": "Adrian",
        "family": "Vladu"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist_challenge and https://github.com/MadryLab/cifar10_challenge.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1706.06083"
  },
  {
    "id": "L6xa6qzg",
    "URL": "https://arxiv.org/abs/1710.11469",
    "number": "1710.11469",
    "title": "Conditional Variance Penalties and Domain Shift Robustness",
    "issued": {
      "date-parts": [
        [
          2019,
          4,
          16
        ]
      ]
    },
    "author": [
      {
        "given": "Christina",
        "family": "Heinze-Deml"
      },
      {
        "given": "Nicolai",
        "family": "Meinshausen"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "When training a deep neural network for image classification, one can broadly distinguish between two types of latent features of images that will drive the classification. We can divide latent features into (i) \"core\" or \"conditionally invariant\" features $X^\\text{core}$ whose distribution $X^\\text{core}\\vert Y$, conditional on the class $Y$, does not change substantially across domains and (ii) \"style\" features $X^{\\text{style}}$ whose distribution $X^{\\text{style}} \\vert Y$ can change substantially across domains. Examples for style features include position, rotation, image quality or brightness but also more complex ones like hair color, image quality or posture for images of persons. Our goal is to minimize a loss that is robust under changes in the distribution of these style features. In contrast to previous work, we assume that the domain itself is not observed and hence a latent variable.\n  We do assume that we can sometimes observe a typically discrete identifier or \"$\\mathrm{ID}$ variable\". In some applications we know, for example, that two images show the same person, and $\\mathrm{ID}$ then refers to the identity of the person. The proposed method requires only a small fraction of images to have $\\mathrm{ID}$ information. We group observations if they share the same class and identifier $(Y,\\mathrm{ID})=(y,\\mathrm{id})$ and penalize the conditional variance of the prediction or the loss if we condition on $(Y,\\mathrm{ID})$. Using a causal framework, this conditional variance regularization (CoRe) is shown to protect asymptotically against shifts in the distribution of the style variables. Empirically, we show that the CoRe penalty improves predictive accuracy substantially in settings where domain changes occur in terms of image quality, brightness and color while we also look at more complex changes such as changes in movement and posture.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1710.11469"
  },
  {
    "id": "ylSNfYug",
    "URL": "https://arxiv.org/abs/1805.12152",
    "number": "1805.12152",
    "title": "Robustness May Be at Odds with Accuracy",
    "issued": {
      "date-parts": [
        [
          2019,
          9,
          10
        ]
      ]
    },
    "author": [
      {
        "given": "Dimitris",
        "family": "Tsipras"
      },
      {
        "given": "Shibani",
        "family": "Santurkar"
      },
      {
        "given": "Logan",
        "family": "Engstrom"
      },
      {
        "given": "Alexander",
        "family": "Turner"
      },
      {
        "given": "Aleksander",
        "family": "Madry"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1805.12152"
  },
  {
    "id": "FJALdE9T",
    "URL": "https://arxiv.org/abs/1811.04383",
    "number": "1811.04383",
    "title": "Adapting multi-armed bandits policies to contextual bandits scenarios",
    "issued": {
      "date-parts": [
        [
          2019,
          11,
          26
        ]
      ]
    },
    "author": [
      {
        "given": "David",
        "family": "Cortes"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "This work explores adaptations of successful multi-armed bandits policies to the online contextual bandits scenario with binary rewards using binary classification algorithms such as logistic regression as black-box oracles. Some of these adaptations are achieved through bootstrapping or approximate bootstrapping, while others rely on other forms of randomness, resulting in more scalable approaches than previous works, and the ability to work with any type of classification algorithm. In particular, the Adaptive-Greedy algorithm shows a lot of promise, in many cases achieving better performance than upper confidence bound and Thompson sampling strategies, at the expense of more hyperparameters to tune.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1811.04383"
  },
  {
    "id": "1DeCFT6PA",
    "URL": "https://arxiv.org/abs/1907.02893",
    "number": "1907.02893",
    "title": "Invariant Risk Minimization",
    "issued": {
      "date-parts": [
        [
          2020,
          3,
          31
        ]
      ]
    },
    "author": [
      {
        "given": "Martin",
        "family": "Arjovsky"
      },
      {
        "given": "LÃ©on",
        "family": "Bottou"
      },
      {
        "given": "Ishaan",
        "family": "Gulrajani"
      },
      {
        "given": "David",
        "family": "Lopez-Paz"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1907.02893"
  },
  {
    "id": "Jm8Kx8HW",
    "URL": "https://arxiv.org/abs/1911.08731",
    "number": "1911.08731",
    "title": "Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization",
    "issued": {
      "date-parts": [
        [
          2020,
          4,
          3
        ]
      ]
    },
    "author": [
      {
        "given": "Shiori",
        "family": "Sagawa"
      },
      {
        "given": "Pang Wei",
        "family": "Koh"
      },
      {
        "given": "Tatsunori B.",
        "family": "Hashimoto"
      },
      {
        "given": "Percy",
        "family": "Liang"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---a stronger-than-typical L2 penalty or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1911.08731"
  },
  {
    "id": "IdMLJI3A",
    "URL": "https://arxiv.org/abs/1911.12568",
    "number": "1911.12568",
    "title": "Optimal Estimation of Change in a Population of Parameters",
    "issued": {
      "date-parts": [
        [
          2019,
          12,
          2
        ]
      ]
    },
    "author": [
      {
        "given": "Ramya Korlakai",
        "family": "Vinayak"
      },
      {
        "given": "Weihao",
        "family": "Kong"
      },
      {
        "given": "Sham M.",
        "family": "Kakade"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Paired estimation of change in parameters of interest over a population plays a central role in several application domains including those in the social sciences, epidemiology, medicine and biology. In these domains, the size of the population under study is often very large, however, the number of observations available per individual in the population is very small (\\emph{sparse observations}) which makes the problem challenging. Consider the setting with $N$ independent individuals, each with unknown parameters $(p_i, q_i)$ drawn from some unknown distribution on $[0, 1]^2$. We observe $X_i \\sim \\text{Bin}(t, p_i)$ before an event and $Y_i \\sim \\text{Bin}(t, q_i)$ after the event. Provided these paired observations, $\\{(X_i, Y_i) \\}_{i=1}^N$, our goal is to accurately estimate the \\emph{distribution of the change in parameters}, $Î´_i := q_i - p_i$, over the population and properties of interest like the \\emph{$\\ell_1$-magnitude of the change} with sparse observations ($t\\ll N$). We provide \\emph{information theoretic lower bounds} on the error in estimating the distribution of change and the $\\ell_1$-magnitude of change. Furthermore, we show that the following two step procedure achieves the optimal error bounds: first, estimate the full joint distribution of the paired parameters using the maximum likelihood estimator (MLE) and then estimate the distribution of change and the $\\ell_1$-magnitude of change using the joint MLE. Notably, and perhaps surprisingly, these error bounds are of the same order as the minimax optimal error bounds for learning the \\emph{full} joint distribution itself (in Wasserstein-1 distance); in other words, estimating the magnitude of the change of parameters over the population is, in a minimax sense, as difficult as estimating the full joint distribution itself.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:1911.12568"
  },
  {
    "id": "lwLz9yZT",
    "URL": "https://arxiv.org/abs/2002.10384",
    "number": "2002.10384",
    "title": "On the Sample Complexity of Adversarial Multi-Source PAC Learning",
    "issued": {
      "date-parts": [
        [
          2020,
          7,
          1
        ]
      ]
    },
    "author": [
      {
        "given": "Nikola",
        "family": "Konstantinov"
      },
      {
        "given": "Elias",
        "family": "Frantar"
      },
      {
        "given": "Dan",
        "family": "Alistarh"
      },
      {
        "given": "Christoph H.",
        "family": "Lampert"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "We study the problem of learning from multiple untrusted data sources, a scenario of increasing practical relevance given the recent emergence of crowdsourcing and collaborative learning paradigms. Specifically, we analyze the situation in which a learning system obtains datasets from multiple sources, some of which might be biased or even adversarially perturbed. It is known that in the single-source case, an adversary with the power to corrupt a fixed fraction of the training data can prevent PAC-learnability, that is, even in the limit of infinitely much training data, no learning system can approach the optimal test error. In this work we show that, surprisingly, the same is not true in the multi-source setting, where the adversary can arbitrarily corrupt a fixed fraction of the data sources. Our main results are a generalization bound that provides finite-sample guarantees for this learning setting, as well as corresponding lower bounds. Besides establishing PAC-learnability our results also show that in a cooperative learning setting sharing data with other parties has provable benefits, even if some participants are malicious.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2002.10384"
  },
  {
    "id": "11IMWGprl",
    "URL": "https://arxiv.org/abs/2003.00688",
    "number": "2003.00688",
    "title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)",
    "issued": {
      "date-parts": [
        [
          2021,
          2,
          26
        ]
      ]
    },
    "author": [
      {
        "given": "David",
        "family": "Krueger"
      },
      {
        "given": "Ethan",
        "family": "Caballero"
      },
      {
        "given": "Joern-Henrik",
        "family": "Jacobsen"
      },
      {
        "given": "Amy",
        "family": "Zhang"
      },
      {
        "given": "Jonathan",
        "family": "Binas"
      },
      {
        "given": "Dinghuai",
        "family": "Zhang"
      },
      {
        "given": "Remi Le",
        "family": "Priol"
      },
      {
        "given": "Aaron",
        "family": "Courville"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Distributional shift is one of the major obstacles when transferring machine learning prediction systems from the lab to the real world. To tackle this problem, we assume that variation across training domains is representative of the variation we might encounter at test time, but also that shifts at test time may be more extreme in magnitude. In particular, we show that reducing differences in risk across training domains can reduce a model's sensitivity to a wide range of extreme distributional shifts, including the challenging setting where the input contains both causal and anti-causal elements. We motivate this approach, Risk Extrapolation (REx), as a form of robust optimization over a perturbation set of extrapolated domains (MM-REx), and propose a penalty on the variance of training risks (V-REx) as a simpler variant. We prove that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution (\"covariate shift\"). By appropriately trading-off robustness to causally induced distributional shifts and covariate shift, REx is able to outperform alternative methods such as Invariant Risk Minimization in situations where these types of shift co-occur.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2003.00688"
  },
  {
    "id": "1FLMzrLE9",
    "URL": "https://arxiv.org/abs/2010.05761",
    "number": "2010.05761",
    "title": "The Risks of Invariant Risk Minimization",
    "issued": {
      "date-parts": [
        [
          2021,
          3,
          30
        ]
      ]
    },
    "author": [
      {
        "given": "Elan",
        "family": "Rosenfeld"
      },
      {
        "given": "Pradeep",
        "family": "Ravikumar"
      },
      {
        "given": "Andrej",
        "family": "Risteski"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Invariant Causal Prediction (Peters et al., 2016) is a technique for out-of-distribution generalization which assumes that some aspects of the data distribution vary across the training set but that the underlying causal mechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant Risk Minimization (IRM), an objective based on this idea for learning deep, invariant features of data which are a complex function of latent variables; many alternatives have subsequently been suggested. However, formal guarantees for all of these works are severely lacking. In this paper, we present the first analysis of classification under the IRM objective--as well as these recently proposed alternatives--under a fairly natural and general model. In the linear case, we show simple conditions under which the optimal solution succeeds or, more often, fails to recover the optimal invariant predictor. We furthermore present the very first results in the non-linear regime: we demonstrate that IRM can fail catastrophically unless the test data are sufficiently similar to the training distribution--this is precisely the issue that it was intended to solve. Thus, in this setting we find that IRM and its alternatives fundamentally do not improve over standard Empirical Risk Minimization.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2010.05761"
  },
  {
    "id": "10151coVE",
    "URL": "https://arxiv.org/abs/2010.07249",
    "number": "2010.07249",
    "title": "Environment Inference for Invariant Learning",
    "issued": {
      "date-parts": [
        [
          2021,
          7,
          16
        ]
      ]
    },
    "author": [
      {
        "given": "Elliot",
        "family": "Creager"
      },
      {
        "given": "JÃ¶rn-Henrik",
        "family": "Jacobsen"
      },
      {
        "given": "Richard",
        "family": "Zemel"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Learning models that gracefully handle distribution shifts is central to research on domain generalization, robust optimization, and fairness. A promising formulation is domain-invariant learning, which identifies the key issue of learning which features are domain-specific versus domain-invariant. An important assumption in this area is that the training examples are partitioned into \"domains\" or \"environments\". Our focus is on the more common setting where such partitions are not provided. We propose EIIL, a general framework for domain-invariant learning that incorporates Environment Inference to directly infer partitions that are maximally informative for downstream Invariant Learning. We show that EIIL outperforms invariant learning methods on the CMNIST benchmark without using environment labels, and significantly outperforms ERM on worst-group performance in the Waterbirds and CivilComments datasets. Finally, we establish connections between EIIL and algorithmic fairness, which enables EIIL to improve accuracy and calibration in a fair prediction problem.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2010.07249"
  },
  {
    "id": "1CkxORTSX",
    "URL": "https://arxiv.org/abs/2103.00315",
    "number": "2103.00315",
    "title": "Time-Varying Coefficient Model Estimation Through Radial Basis Functions",
    "issued": {
      "date-parts": [
        [
          2021,
          3,
          2
        ]
      ]
    },
    "author": [
      {
        "given": "Juan",
        "family": "Sosa"
      },
      {
        "given": "Lina",
        "family": "Buitrago"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "In this paper we estimate the dynamic parameters of a time-varying coefficient model through radial kernel functions in the context of a longitudinal study. Our proposal is based on a linear combination of weighted kernel functions involving a bandwidth, centered around a given set of time points. In addition, we study different alternatives of estimation and inference including a Frequentist approach using weighted least squares along with bootstrap methods, and a Bayesian approach through both Markov chain Monte Carlo and variational methods. We compare the estimation strategies mention above with each other, and our radial kernel functions proposal with an expansion based on regression spline, by means of an extensive simulation study considering multiples scenarios in terms of sample size, number of repeated measurements, and subject-specific correlation. Our experiments show that the capabilities of our proposal based on radial kernel functions are indeed comparable with or even better than those obtained from regression splines. We illustrate our methodology by analyzing data from two AIDS clinical studies.",
    "note": "license: http://arxiv.org/licenses/nonexclusive-distrib/1.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2103.00315"
  },
  {
    "id": "HzzgJQN0",
    "URL": "https://arxiv.org/abs/2106.04486",
    "number": "2106.04486",
    "title": "Sketch-Based Anomaly Detection in Streaming Graphs",
    "issued": {
      "date-parts": [
        [
          2023,
          7,
          18
        ]
      ]
    },
    "author": [
      {
        "given": "Siddharth",
        "family": "Bhatia"
      },
      {
        "given": "Mohit",
        "family": "Wadhwa"
      },
      {
        "given": "Kenji",
        "family": "Kawaguchi"
      },
      {
        "given": "Neil",
        "family": "Shah"
      },
      {
        "given": "Philip S.",
        "family": "Yu"
      },
      {
        "given": "Bryan",
        "family": "Hooi"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges and subgraphs in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? For example, in intrusion detection, existing work seeks to detect either anomalous edges or anomalous subgraphs, but not both. In this paper, we first extend the count-min sketch data structure to a higher-order sketch. This higher-order sketch has the useful property of preserving the dense subgraph structure (dense subgraphs in the input turn into dense submatrices in the data structure). We then propose 4 online algorithms that utilize this enhanced data structure, which (a) detect both edge and graph anomalies; (b) process each edge and graph in constant memory and constant update time per newly arriving edge, and; (c) outperform state-of-the-art baselines on 4 real-world datasets. Our method is the first streaming approach that incorporates dense subgraph search to detect graph anomalies in constant memory and time.",
    "note": "license: http://creativecommons.org/licenses/by/4.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2106.04486"
  },
  {
    "id": "pn0xfUyE",
    "URL": "https://arxiv.org/abs/2110.14048",
    "number": "2110.14048",
    "title": "Conflict-Averse Gradient Descent for Multi-task Learning",
    "issued": {
      "date-parts": [
        [
          2024,
          2,
          22
        ]
      ]
    },
    "author": [
      {
        "given": "Bo",
        "family": "Liu"
      },
      {
        "given": "Xingchao",
        "family": "Liu"
      },
      {
        "given": "Xiaojie",
        "family": "Jin"
      },
      {
        "given": "Peter",
        "family": "Stone"
      },
      {
        "given": "Qiang",
        "family": "Liu"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "The goal of multi-task learning is to enable more efficient learning than single task learning by sharing model structures for a diverse set of tasks. A standard multi-task learning objective is to minimize the average loss across all tasks. While straightforward, using this objective often results in much worse final performance for each task than learning them independently. A major challenge in optimizing a multi-task model is the conflicting gradients, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks' performance. Previous work has proposed several heuristics to manipulate the task gradients for mitigating this problem. But most of them lack convergence guarantee and/or could converge to any Pareto-stationary point. In this paper, we introduce Conflict-Averse Gradient descent (CAGrad) which minimizes the average loss function, while leveraging the worst local improvement of individual tasks to regularize the algorithm trajectory. CAGrad balances the objectives automatically and still provably converges to a minimum over the average loss. It includes the regular gradient descent (GD) and the multiple gradient descent algorithm (MGDA) in the multi-objective optimization (MOO) literature as special cases. On a series of challenging multi-task supervised learning and reinforcement learning tasks, CAGrad achieves improved performance over prior state-of-the-art multi-objective gradient manipulation methods.",
    "note": "license: http://creativecommons.org/licenses/by/4.0/\nThis CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: arxiv:2110.14048"
  },
  {
    "id": "193MlihYp",
    "type": "article-journal",
    "author": [
      {
        "family": "Bommasani",
        "given": "Rishi"
      },
      {
        "family": "Hudson",
        "given": "Drew A."
      },
      {
        "family": "Adeli",
        "given": "Ehsan"
      },
      {
        "family": "Altman",
        "given": "Russ"
      },
      {
        "family": "Arora",
        "given": "Simran"
      }
    ],
    "title": "On the Opportunities and Risks of Foundation Models",
    "container-title": "arXiv preprint arXiv:2108.07258",
    "note": "and other authors\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: bommasani2021opportunities"
  },
  {
    "id": "R5HQsIG9",
    "type": "article-journal",
    "author": [
      {
        "family": "Bottou",
        "given": "Léon"
      },
      {
        "family": "Curtis",
        "given": "Frank E."
      },
      {
        "family": "Nocedal",
        "given": "Jorge"
      }
    ],
    "title": "Optimization methods for large-scale machine learning",
    "container-title": "SIAM Review",
    "volume": "60",
    "issue": "2",
    "page": "223--311",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: bottou2018optimization"
  },
  {
    "id": "159keZX88",
    "type": "article-journal",
    "author": [
      {
        "family": "Botzer",
        "given": "Assaf"
      }
    ],
    "title": "Publication Trends on the Varying Coefficients Model: Estimating the Actual (Under)Utilization of a Highly Acclaimed Method for Studying Statistical Interactions",
    "container-title": "Publications",
    "volume": "13",
    "issue": "2",
    "page": "19",
    "DOI": "10.3390/publications13020019",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: botzer2025publication"
  },
  {
    "id": "Bgxj9luJ",
    "type": "article-journal",
    "author": [
      {
        "family": "Boyd",
        "given": "Stephen"
      },
      {
        "family": "Parikh",
        "given": "Neal"
      },
      {
        "family": "Chu",
        "given": "Eric"
      },
      {
        "family": "Peleato",
        "given": "Brendan"
      },
      {
        "family": "Eckstein",
        "given": "Jonathan"
      }
    ],
    "title": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
    "container-title": "Foundations and Trends in Machine Learning",
    "volume": "3",
    "issue": "1",
    "page": "1--122",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: boyd2011distributed"
  },
  {
    "id": "16GpbreXJ",
    "type": "paper-conference",
    "author": [
      {
        "family": "Brown",
        "given": "Tom B."
      },
      {
        "family": "Mann",
        "given": "Benjamin"
      },
      {
        "family": "Ryder",
        "given": "Nick"
      },
      {
        "family": "Subbiah",
        "given": "Melanie"
      },
      {
        "family": "Kaplan",
        "given": "Jared"
      },
      {
        "family": "Dhariwal",
        "given": "Prafulla"
      },
      {
        "family": "Neelakantan",
        "given": "Arvind"
      },
      {
        "family": "Shyam",
        "given": "Pranav"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Askell",
        "given": "Amanda"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Herbert-Voss",
        "given": "Ariel"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Henighan",
        "given": "Tom"
      },
      {
        "family": "Child",
        "given": "Rewon"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Ziegler",
        "given": "Daniel M."
      },
      {
        "family": "Wu",
        "given": "Jeffrey"
      },
      {
        "family": "Winter",
        "given": "Clemens"
      },
      {
        "family": "Hesse",
        "given": "Christopher"
      },
      {
        "family": "Chen",
        "given": "Mark"
      },
      {
        "family": "Sigler",
        "given": "Eric"
      },
      {
        "family": "Litwin",
        "given": "Mateusz"
      },
      {
        "family": "Gray",
        "given": "Scott"
      },
      {
        "family": "Chess",
        "given": "Benjamin"
      },
      {
        "family": "Clark",
        "given": "Jack"
      },
      {
        "family": "Berner",
        "given": "Christopher"
      },
      {
        "family": "McCandlish",
        "given": "Sam"
      },
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Amodei",
        "given": "Dario"
      }
    ],
    "title": "Language Models are Few-Shot Learners",
    "container-title": "Advances in Neural Information Processing Systems 33",
    "page": "1877--1901",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: brown2020language"
  },
  {
    "id": "1GTolz1Ss",
    "type": "manuscript",
    "author": [
      {
        "family": "Cheng",
        "given": "Yu"
      },
      {
        "family": "Yang",
        "given": "Dongdong"
      },
      {
        "family": "Zhou",
        "given": "Denny"
      }
    ],
    "title": "XGBoost-Inspired Estimation for High-Dimensional Varying Coefficient Models",
    "archive": "arXiv",
    "note": "stat.ML\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: cheng2020xgboost"
  },
  {
    "id": "uSkZkc4u",
    "type": "manuscript",
    "author": [
      {
        "family": "Dai",
        "given": "Damai"
      },
      {
        "family": "Sun",
        "given": "Yutao"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Hao",
        "given": "Yaru"
      },
      {
        "family": "Ma",
        "given": "Shuming"
      },
      {
        "family": "Sui",
        "given": "Zhifang"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "title": "Why Can GPT Learn In-Context? Language Models as Meta-Learners",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: dai2022can"
  },
  {
    "id": "19AlWXYPF",
    "type": "paper-conference",
    "author": [
      {
        "family": "Dai",
        "given": "Damai"
      },
      {
        "family": "Dong",
        "given": "Li"
      },
      {
        "family": "Sun",
        "given": "Yutao"
      },
      {
        "family": "Ma",
        "given": "Shuming"
      },
      {
        "family": "Wei",
        "given": "Furu"
      }
    ],
    "title": "Knowledge Neurons in Pretrained Transformers",
    "container-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: dai2022knowledge"
  },
  {
    "publisher": "Springer Berlin Heidelberg",
    "DOI": "10.1007/978-3-540-45167-9_23",
    "type": "chapter",
    "page": "303-313",
    "source": "Crossref",
    "title": "Optimal Rates of Aggregation",
    "author": [
      {
        "given": "Alexandre B.",
        "family": "Tsybakov"
      }
    ],
    "container-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "URL": "https://doi.org/czntw5",
    "id": "12npMQT1q",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/978-3-540-45167-9_23"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "2",
    "DOI": "10.1007/s10462-012-9338-y",
    "type": "article-journal",
    "page": "275-293",
    "source": "Crossref",
    "title": "Mixture of experts: a literature survey",
    "volume": "42",
    "author": [
      {
        "given": "Saeed",
        "family": "Masoudnia"
      },
      {
        "given": "Reza",
        "family": "Ebrahimpour"
      }
    ],
    "container-title": "Artificial Intelligence Review",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2012,
          5,
          12
        ]
      ]
    },
    "URL": "https://doi.org/f59sxs",
    "container-title-short": "Artif Intell Rev",
    "id": "g7RE7G0h",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1007/s10462-012-9338-y"
  },
  {
    "publisher": "Elsevier BV",
    "DOI": "10.1016/j.jbi.2022.104086",
    "type": "article-journal",
    "page": "104086",
    "source": "Crossref",
    "title": "Automated interpretable discovery of heterogeneous treatment effectiveness: A COVID-19 case study",
    "volume": "130",
    "author": [
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Mark E.",
        "family": "Nunnally"
      },
      {
        "given": "Yin",
        "family": "Aphinyanaphongs"
      },
      {
        "given": "Caleb",
        "family": "Ellington"
      },
      {
        "given": "Rich",
        "family": "Caruana"
      }
    ],
    "container-title": "Journal of Biomedical Informatics",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          6
        ]
      ]
    },
    "URL": "https://doi.org/gt68h5",
    "container-title-short": "Journal of Biomedical Informatics",
    "PMCID": "PMC9055753",
    "PMID": "35504543",
    "id": "esxxcr9l",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1016/j.jbi.2022.104086"
  },
  {
    "publisher": "Springer Science and Business Media LLC",
    "issue": "1",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Recent large language models (LLMs), such as ChatGPT, have demonstrated remarkable prediction performance for a growing array of tasks. However, their proliferation into high-stakes domains and compute-limited settings has created a burgeoning need for interpretability and efficiency. We address this need by proposing Aug-imodels, a framework for leveraging the knowledge learned by LLMs to build extremely efficient and interpretable prediction models. Aug-imodels use LLMs during fitting but not during inference, allowing complete transparency and often a speed/memory improvement of greater than 1000x for inference compared to LLMs. We explore two instantiations of Aug-imodels in natural-language processing: Aug-Linear, which augments a linear model with decoupled embeddings from an LLM and Aug-Tree, which augments a decision tree with LLM feature expansions. Across a variety of text-classification datasets, both outperform their non-augmented, interpretable counterparts. Aug-Linear can even outperform much larger models, e.g. a 6-billion parameter GPT-J model, despite having 10,000x fewer parameters and being fully transparent. We further explore Aug-imodels in a natural-language fMRI study, where they generate interesting interpretations from scientific data.</jats:p>",
    "DOI": "10.1038/s41467-023-43713-1",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Augmenting interpretable models with large language models during training",
    "volume": "14",
    "author": [
      {
        "given": "Chandan",
        "family": "Singh"
      },
      {
        "given": "Armin",
        "family": "Askari"
      },
      {
        "given": "Rich",
        "family": "Caruana"
      },
      {
        "given": "Jianfeng",
        "family": "Gao"
      }
    ],
    "container-title": "Nature Communications",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          11,
          30
        ]
      ]
    },
    "URL": "https://doi.org/g9t2z9",
    "container-title-short": "Nat Commun",
    "PMCID": "PMC10689442",
    "PMID": "38036543",
    "id": "HQXzkG4Q",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1038/s41467-023-43713-1"
  },
  {
    "publisher": "Informa UK Limited",
    "issue": "538",
    "DOI": "10.1080/01621459.2021.2000866",
    "type": "article-journal",
    "page": "533-546",
    "source": "Crossref",
    "title": "Bayesian Edge Regression in Undirected Graphical Models to Characterize Interpatient Heterogeneity in Cancer",
    "volume": "117",
    "author": [
      {
        "given": "Zeya",
        "family": "Wang"
      },
      {
        "given": "Veerabhadran",
        "family": "Baladandayuthapani"
      },
      {
        "given": "Ahmed O.",
        "family": "Kaseb"
      },
      {
        "given": "Hesham M.",
        "family": "Amin"
      },
      {
        "given": "Manal M.",
        "family": "Hassan"
      },
      {
        "given": "Wenyi",
        "family": "Wang"
      },
      {
        "given": "Jeffrey S.",
        "family": "Morris"
      }
    ],
    "container-title": "Journal of the American Statistical Association",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2022,
          1,
          5
        ]
      ]
    },
    "URL": "https://doi.org/gt68hr",
    "container-title-short": "Journal of the American Statistical Association",
    "PMCID": "PMC9454401",
    "PMID": "36090952",
    "id": "TULLRYDp",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1080/01621459.2021.2000866"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:title>Abstract</jats:title><jats:p>Summarizing multiple data modalities into a parsimonious cancer “subtype” is difficult because the most informative representation of each patient’s disease is not observed. We propose to model these latent summaries as<jats:italic>discriminative subtypes</jats:italic>: sample representations which induce accurate and interpretable sample-specific models for downstream predictions. In this way, discriminative subtypes, which are shared between data modalities, can be estimated from one data modality and optimized according to the predictions induced in another modality. We apply this approach to lung cancer by training a deep neural network to predict discriminative subtypes from histopathology images, and use these predicted subtypes to generate models which classify adenocarcinoma, squamous cell carcinoma, and healthy tissue based on transcriptomic signatures. In this way, we optimize the latent discriminative subtypes through induced prediction loss, and the discriminative subtypes are interpreted with standard interpretation of transcriptomic predictive models. Our framework achieves state-of-the-art classification accuracy (F1-score of 0.97) and identifies discriminative subtypes which link histopathology images to transcriptomic explanations without requiring pre-specification of morphological patterns or transcriptomic processes.</jats:p>",
    "DOI": "10.1101/2020.06.25.20140053",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Discriminative Subtyping of Lung Cancers from Histopathology Images via Contextual Deep Learning",
    "author": [
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Maruan",
        "family": "Al-Shedivat"
      },
      {
        "given": "Amir",
        "family": "Alavi"
      },
      {
        "given": "Jennifer",
        "family": "Williams"
      },
      {
        "given": "Sami",
        "family": "Labbaki"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2020,
          6,
          26
        ]
      ]
    },
    "URL": "https://doi.org/gt68h6",
    "id": "O1UU4a5P",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2020.06.25.20140053"
  },
  {
    "publisher": "Cold Spring Harbor Laboratory",
    "abstract": "<jats:p>Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory networks (GRNs) from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond coarse analyses of pre-defined subgroups by using<jats:italic>contextualized</jats:italic>learning, a multi-task learning paradigm that uses multi-view contexts including phenotypic, molecular, and environmental information to infer personalized models. With sample-specific contexts, contextualization enables sample-specific models and even generalizes at test time to predict network models for entirely unseen contexts. We unify three network model classes (Correlation, Markov, Neighborhood Selection) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, using copy number and driver mutation profiles, tumor microenvironment, and patient demographics as model context. Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology by providing a structured view of expression dynamics at sample-specific resolution, explaining known biomarkers in terms of network-mediated effects and leading to novel subtypings that improve survival prognosis. We provide a SKLearn-style Python package<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://contextualized.ml\">https://contextualized.ml</jats:ext-link>for learning and analyzing contextualized models, as well as interactive plotting tools for pan-cancer data exploration at<jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/cnellington/CancerContextualized\">https://github.com/cnellington/CancerContextualized</jats:ext-link>.</jats:p><jats:sec><jats:title>Significance Statement</jats:title><jats:p>Network estimation is essential for understanding the structure and function of biological systems, but current statistical approaches fail to capture inter-subject heterogeneity or cross-modality information flow, both of which are needed for understanding complex phenotypes and pathologies. We introduce contextualized network inference, leveraging multi-view contextual metadata to capture similarities and differences among heterogeneous observations during network estimation. Sharing information across contexts enables inference at sample-specific resolution, thus quantifying variation between subjects and revealing context-specific network rewiring. Applied to tumor-specific transcriptional network inference using clinical, molecular, and multi-omic data, contextualized networks improve accuracy, generalize to unseen cancer types, and discover novel prognostic tumor subtypes. By tailoring disease models to each sample, contextualized networks promise to enable precision medicine at unprecedented resolution.</jats:p></jats:sec>",
    "DOI": "10.1101/2023.12.01.569658",
    "type": "manuscript",
    "source": "Crossref",
    "title": "Learning to Estimate Sample-specific Transcriptional Networks for 7000 Tumors",
    "author": [
      {
        "given": "Caleb N.",
        "family": "Ellington"
      },
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Thomas B.K.",
        "family": "Watkins"
      },
      {
        "given": "Jiekun",
        "family": "Yang"
      },
      {
        "given": "Abhinav",
        "family": "Adduri"
      },
      {
        "given": "Sazan",
        "family": "Mahbub"
      },
      {
        "given": "Hanxi",
        "family": "Xiao"
      },
      {
        "given": "Manolis",
        "family": "Kellis"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023,
          12,
          4
        ]
      ]
    },
    "URL": "https://doi.org/gt68h7",
    "id": "Rt6voTFN",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1101/2023.12.01.569658"
  },
  {
    "publisher": "Oxford University Press (OUP)",
    "issue": "4",
    "abstract": "<jats:title>SUMMARY</jats:title>\n               <jats:p>We explore a class of regression and generalized regression models in which the coefficients are allowed to vary as smooth functions of other variables. General algorithms are presented for estimating the models flexibly and some examples are given. This class of models ties together generalized additive models and dynamic generalized linear models into one common framework. When applied to the proportional hazards model for survival data, this approach provides a new way of modelling departures from the proportional hazards assumption.</jats:p>",
    "DOI": "10.1111/j.2517-6161.1993.tb01939.x",
    "type": "article-journal",
    "page": "757-779",
    "source": "Crossref",
    "title": "Varying-Coefficient Models",
    "volume": "55",
    "author": [
      {
        "given": "Trevor",
        "family": "Hastie"
      },
      {
        "given": "Robert",
        "family": "Tibshirani"
      }
    ],
    "container-title": "Journal of the Royal Statistical Society Series B: Statistical Methodology",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          1993,
          9,
          1
        ]
      ]
    },
    "URL": "https://doi.org/gmfvmb",
    "id": "ugXwusl0",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1111/j.2517-6161.1993.tb01939.x"
  },
  {
    "publisher": "ACM",
    "DOI": "10.1145/2783258.2788613",
    "type": "paper-conference",
    "page": "1721-1730",
    "source": "Crossref",
    "title": "Intelligible Models for HealthCare",
    "author": [
      {
        "given": "Rich",
        "family": "Caruana"
      },
      {
        "given": "Yin",
        "family": "Lou"
      },
      {
        "given": "Johannes",
        "family": "Gehrke"
      },
      {
        "given": "Paul",
        "family": "Koch"
      },
      {
        "given": "Marc",
        "family": "Sturm"
      },
      {
        "given": "Noemie",
        "family": "Elhadad"
      }
    ],
    "event": "KDD '15: The 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
    "container-title": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
    "issued": {
      "date-parts": [
        [
          2015,
          8,
          10
        ]
      ]
    },
    "URL": "https://doi.org/gftgxk",
    "id": "gSmt16Rh",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1145/2783258.2788613"
  },
  {
    "publisher": "ACM",
    "DOI": "10.1145/3097983.3098066",
    "type": "paper-conference",
    "page": "275-284",
    "source": "Crossref",
    "title": "The Selective Labels Problem",
    "author": [
      {
        "given": "Himabindu",
        "family": "Lakkaraju"
      },
      {
        "given": "Jon",
        "family": "Kleinberg"
      },
      {
        "given": "Jure",
        "family": "Leskovec"
      },
      {
        "given": "Jens",
        "family": "Ludwig"
      },
      {
        "given": "Sendhil",
        "family": "Mullainathan"
      }
    ],
    "event": "KDD '17: The 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
    "container-title": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
    "issued": {
      "date-parts": [
        [
          2017,
          8,
          4
        ]
      ]
    },
    "URL": "https://doi.org/ggd7hz",
    "PMCID": "PMC5958915",
    "PMID": "29780658",
    "id": "MGkiKe9y",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1145/3097983.3098066"
  },
  {
    "publisher": "Association for Computing Machinery (ACM)",
    "issue": "9",
    "abstract": "<jats:p>\n            This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input\n            <jats:bold>\n              <jats:italic>x</jats:italic>\n            </jats:bold>\n            and predict an output\n            <jats:bold>\n              <jats:italic>y</jats:italic>\n            </jats:bold>\n            as\n            <jats:italic>P</jats:italic>\n            (\n            <jats:bold>\n              <jats:italic>y|x</jats:italic>\n            </jats:bold>\n            ), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input\n            <jats:bold>\n              <jats:italic>x</jats:italic>\n            </jats:bold>\n            is modified using a\n            <jats:italic>template</jats:italic>\n            into a textual string\n            <jats:italic>prompt</jats:italic>\n            <jats:bold>\n              <jats:italic>x′</jats:italic>\n            </jats:bold>\n            that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string\n            <jats:bold>\n              <jats:italic>x̂</jats:italic>\n            </jats:bold>\n            , from which the final output\n            <jats:bold>\n              <jats:italic>y</jats:italic>\n            </jats:bold>\n            can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be\n            <jats:italic>pre-trained</jats:italic>\n            on massive amounts of raw text, and by defining a new prompting function the model is able to perform\n            <jats:italic>few-shot</jats:italic>\n            or even\n            <jats:italic>zero-shot</jats:italic>\n            learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website\n            <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"url\" xlink:href=\"http://pretrain.nlpedia.ai/\">NLPedia–Pretrain</jats:ext-link>\n            including constantly updated survey and paperlist.\n          </jats:p>",
    "DOI": "10.1145/3560815",
    "type": "article-journal",
    "page": "1-35",
    "source": "Crossref",
    "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
    "volume": "55",
    "author": [
      {
        "given": "Pengfei",
        "family": "Liu"
      },
      {
        "given": "Weizhe",
        "family": "Yuan"
      },
      {
        "given": "Jinlan",
        "family": "Fu"
      },
      {
        "given": "Zhengbao",
        "family": "Jiang"
      },
      {
        "given": "Hiroaki",
        "family": "Hayashi"
      },
      {
        "given": "Graham",
        "family": "Neubig"
      }
    ],
    "container-title": "ACM Computing Surveys",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2023,
          1,
          16
        ]
      ]
    },
    "URL": "https://doi.org/gq5fh2",
    "container-title-short": "ACM Comput. Surv.",
    "id": "12nAa0T4v",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1145/3560815"
  },
  {
    "publisher": "Institute of Mathematical Statistics",
    "issue": "1",
    "DOI": "10.1214/09-aoas308",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Estimating time-varying networks",
    "volume": "4",
    "author": [
      {
        "given": "Mladen",
        "family": "Kolar"
      },
      {
        "given": "Le",
        "family": "Song"
      },
      {
        "given": "Amr",
        "family": "Ahmed"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "container-title": "The Annals of Applied Statistics",
    "issued": {
      "date-parts": [
        [
          2010,
          3,
          1
        ]
      ]
    },
    "URL": "https://doi.org/b3rn6q",
    "container-title-short": "Ann. Appl. Stat.",
    "id": "lAsTg3IH",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1214/09-aoas308"
  },
  {
    "publisher": "Institute of Mathematical Statistics",
    "issue": "5",
    "DOI": "10.1214/aos/1017939139",
    "type": "article-journal",
    "source": "Crossref",
    "title": "Statistical estimation in varying coefficient models",
    "volume": "27",
    "author": [
      {
        "given": "Jianqing",
        "family": "Fan"
      },
      {
        "given": "Wenyang",
        "family": "Zhang"
      }
    ],
    "container-title": "The Annals of Statistics",
    "issued": {
      "date-parts": [
        [
          1999,
          10,
          1
        ]
      ]
    },
    "URL": "https://doi.org/dsxd4s",
    "container-title-short": "Ann. Statist.",
    "id": "l6vMkIsa",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.1214/aos/1017939139"
  },
  {
    "publisher": "Association for Computational Linguistics",
    "DOI": "10.18653/v1/2023.emnlp-main.384",
    "type": "paper-conference",
    "page": "6253-6267",
    "source": "Crossref",
    "title": "Tree Prompting: Efficient Task Adaptation without Fine-Tuning",
    "author": [
      {
        "given": "Chandan",
        "family": "Singh"
      },
      {
        "given": "John",
        "family": "Morris"
      },
      {
        "given": "Alexander",
        "family": "Rush"
      },
      {
        "given": "Jianfeng",
        "family": "Gao"
      },
      {
        "given": "Yuntian",
        "family": "Deng"
      }
    ],
    "event": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    "container-title": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "URL": "https://doi.org/gtgrkq",
    "id": "kAJDlMwy",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.18653/v1/2023.emnlp-main.384"
  },
  {
    "publisher": "The Open Journal",
    "issue": "97",
    "DOI": "10.21105/joss.06469",
    "type": "article-journal",
    "page": "6469",
    "source": "Crossref",
    "title": "Contextualized: Heterogeneous Modeling Toolbox",
    "volume": "9",
    "author": [
      {
        "given": "Caleb N.",
        "family": "Ellington"
      },
      {
        "given": "Benjamin J.",
        "family": "Lengerich"
      },
      {
        "given": "Wesley",
        "family": "Lo"
      },
      {
        "given": "Aaron",
        "family": "Alvarez"
      },
      {
        "given": "Andrea",
        "family": "Rubbi"
      },
      {
        "given": "Manolis",
        "family": "Kellis"
      },
      {
        "given": "Eric P.",
        "family": "Xing"
      }
    ],
    "container-title": "Journal of Open Source Software",
    "issued": {
      "date-parts": [
        [
          2024,
          5,
          8
        ]
      ]
    },
    "URL": "https://doi.org/gt68h8",
    "container-title-short": "JOSS",
    "id": "4cK1tiec",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.21105/joss.06469"
  },
  {
    "publisher": "MDPI AG",
    "issue": "3",
    "abstract": "<jats:p>Complex diseases such as type 2 diabetes are influenced by both environmental and genetic risk factors, leading to a growing interest in identifying gene–environment (G × E) interactions. A three-step variable selection method for single-index varying-coefficients models was proposed in recent research. This method selects varying and constant-effect genetic predictors, as well as non-zero loading parameters, to identify genetic factors that interact linearly or nonlinearly with a mixture of environmental factors to influence disease risk. In this paper, we extend this approach to a binary response setting given that many complex human diseases are binary traits. We also establish the oracle property for our variable selection method, demonstrating that it performs as well as if the correct sub-model were known in advance. Additionally, we assess the performance of our method through finite-sample simulations with both continuous and discrete gene variables. Finally, we apply our approach to a type 2 diabetes dataset, identifying potential genetic factors that interact with a combination of environmental variables, both linearly and nonlinearly, to influence the risk of developing type 2 diabetes.</jats:p>",
    "DOI": "10.3390/math13030469",
    "type": "article-journal",
    "page": "469",
    "source": "Crossref",
    "title": "Variable Selection for Generalized Single-Index Varying-Coefficient Models with Applications to Synergistic G × E Interactions",
    "volume": "13",
    "author": [
      {
        "given": "Shunjie",
        "family": "Guan"
      },
      {
        "given": "Xu",
        "family": "Liu"
      },
      {
        "given": "Yuehua",
        "family": "Cui"
      }
    ],
    "container-title": "Mathematics",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2025,
          1,
          31
        ]
      ]
    },
    "URL": "https://doi.org/g9t2rp",
    "container-title-short": "Mathematics",
    "id": "dvWlfk21",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.3390/math13030469"
  },
  {
    "type": "article",
    "id": "SfCo6pSp",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Al-Shedivat",
        "given": "Maruan"
      },
      {
        "family": "Dubey",
        "given": "Avinava"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "abstract": "Modern learning algorithms excel at producing accurate but complex models of the data. However, deploying such models in the real-world requires extra care: we must ensure their reliability, robustness, and absence of undesired biases. This motivates the development of models that are equally accurate but can be also easily inspected and assessed beyond their predictive performance. To this end, we introduce contextual explanation networks (CEN)---a class of architectures that learn to predict by generating and utilizing intermediate, simplified probabilistic models. Specifically, CENs generate parameters for intermediate graphical models which are further used for prediction and play the role of explanations. Contrary to the existing post-hoc model-explanation tools, CENs learn to predict and to explain simultaneously. Our approach offers two major advantages: (i) for each prediction valid, instance-specific explanation is generated with no computational overhead and (ii) prediction via explanation acts as a regularizer and boosts performance in data-scarce settings. We analyze the proposed framework theoretically and experimentally. Our results on image and text classification and survival analysis tasks demonstrate that CENs are not only competitive with the state-of-the-art methods but also offer additional insights behind each prediction, that can be valuable for decision support. We also show that while post-hoc methods may produce misleading explanations in certain cases, CENs are consistent and allow to detect such cases systematically.",
    "DOI": "10.48550/arxiv.1705.10301",
    "publisher": "arXiv",
    "title": "Contextual Explanation Networks",
    "URL": "https://doi.org/gt68h9",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1705.10301"
  },
  {
    "type": "article",
    "id": "urJgpE6q",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Devlin",
        "given": "Jacob"
      },
      {
        "family": "Chang",
        "given": "Ming-Wei"
      },
      {
        "family": "Lee",
        "given": "Kenton"
      },
      {
        "family": "Toutanova",
        "given": "Kristina"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
    "DOI": "10.48550/arxiv.1810.04805",
    "publisher": "arXiv",
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "URL": "https://doi.org/hm65",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1810.04805"
  },
  {
    "type": "article",
    "id": "WlwUpYp",
    "categories": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Benjamin"
      },
      {
        "family": "Aragam",
        "given": "Bryon"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "abstract": "Modern applications of machine learning (ML) deal with increasingly heterogeneous datasets comprised of data collected from overlapping latent subpopulations. As a result, traditional models trained over large datasets may fail to recognize highly predictive localized effects in favour of weakly predictive global patterns. This is a problem because localized effects are critical to developing individualized policies and treatment plans in applications ranging from precision medicine to advertising. To address this challenge, we propose to estimate sample-specific models that tailor inference and prediction at the individual level. In contrast to classical ML models that estimate a single, complex model (or only a few complex models), our approach produces a model personalized to each sample. These sample-specific models can be studied to understand subgroup dynamics that go beyond coarse-grained class labels. Crucially, our approach does not assume that relationships between samples (e.g. a similarity network) are known a priori. Instead, we use unmodeled covariates to learn a latent distance metric over the samples. We apply this approach to financial, biomedical, and electoral data as well as simulated data and show that sample-specific models provide fine-grained interpretations of complicated phenomena without sacrificing predictive accuracy compared to state-of-the-art models such as deep neural networks.",
    "DOI": "10.48550/arxiv.1910.06939",
    "publisher": "arXiv",
    "title": "Learning Sample-Specific Models with Low-Rank Personalized Regression",
    "URL": "https://doi.org/gt68jb",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.1910.06939"
  },
  {
    "type": "article",
    "id": "17tnf46zM",
    "categories": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Kim",
        "given": "Jong Wook"
      },
      {
        "family": "Hallacy",
        "given": "Chris"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Goh",
        "given": "Gabriel"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Askell",
        "given": "Amanda"
      },
      {
        "family": "Mishkin",
        "given": "Pamela"
      },
      {
        "family": "Clark",
        "given": "Jack"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.",
    "DOI": "10.48550/arxiv.2103.00020",
    "publisher": "arXiv",
    "title": "Learning Transferable Visual Models From Natural Language Supervision",
    "URL": "https://doi.org/hs7z",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2103.00020"
  },
  {
    "type": "article",
    "id": "1GbAsSOZV",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Bommasani",
        "given": "Rishi"
      },
      {
        "family": "Hudson",
        "given": "Drew A."
      },
      {
        "family": "Adeli",
        "given": "Ehsan"
      },
      {
        "family": "Altman",
        "given": "Russ"
      },
      {
        "family": "Arora",
        "given": "Simran"
      },
      {
        "family": "von Arx",
        "given": "Sydney"
      },
      {
        "family": "Bernstein",
        "given": "Michael S."
      },
      {
        "family": "Bohg",
        "given": "Jeannette"
      },
      {
        "family": "Bosselut",
        "given": "Antoine"
      },
      {
        "family": "Brunskill",
        "given": "Emma"
      },
      {
        "family": "Brynjolfsson",
        "given": "Erik"
      },
      {
        "family": "Buch",
        "given": "Shyamal"
      },
      {
        "family": "Card",
        "given": "Dallas"
      },
      {
        "family": "Castellon",
        "given": "Rodrigo"
      },
      {
        "family": "Chatterji",
        "given": "Niladri"
      },
      {
        "family": "Chen",
        "given": "Annie"
      },
      {
        "family": "Creel",
        "given": "Kathleen"
      },
      {
        "family": "Davis",
        "given": "Jared Quincy"
      },
      {
        "family": "Demszky",
        "given": "Dora"
      },
      {
        "family": "Donahue",
        "given": "Chris"
      },
      {
        "family": "Doumbouya",
        "given": "Moussa"
      },
      {
        "family": "Durmus",
        "given": "Esin"
      },
      {
        "family": "Ermon",
        "given": "Stefano"
      },
      {
        "family": "Etchemendy",
        "given": "John"
      },
      {
        "family": "Ethayarajh",
        "given": "Kawin"
      },
      {
        "family": "Fei-Fei",
        "given": "Li"
      },
      {
        "family": "Finn",
        "given": "Chelsea"
      },
      {
        "family": "Gale",
        "given": "Trevor"
      },
      {
        "family": "Gillespie",
        "given": "Lauren"
      },
      {
        "family": "Goel",
        "given": "Karan"
      },
      {
        "family": "Goodman",
        "given": "Noah"
      },
      {
        "family": "Grossman",
        "given": "Shelby"
      },
      {
        "family": "Guha",
        "given": "Neel"
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori"
      },
      {
        "family": "Henderson",
        "given": "Peter"
      },
      {
        "family": "Hewitt",
        "given": "John"
      },
      {
        "family": "Ho",
        "given": "Daniel E."
      },
      {
        "family": "Hong",
        "given": "Jenny"
      },
      {
        "family": "Hsu",
        "given": "Kyle"
      },
      {
        "family": "Huang",
        "given": "Jing"
      },
      {
        "family": "Icard",
        "given": "Thomas"
      },
      {
        "family": "Jain",
        "given": "Saahil"
      },
      {
        "family": "Jurafsky",
        "given": "Dan"
      },
      {
        "family": "Kalluri",
        "given": "Pratyusha"
      },
      {
        "family": "Karamcheti",
        "given": "Siddharth"
      },
      {
        "family": "Keeling",
        "given": "Geoff"
      },
      {
        "family": "Khani",
        "given": "Fereshte"
      },
      {
        "family": "Khattab",
        "given": "Omar"
      },
      {
        "family": "Koh",
        "given": "Pang Wei"
      },
      {
        "family": "Krass",
        "given": "Mark"
      },
      {
        "family": "Krishna",
        "given": "Ranjay"
      },
      {
        "family": "Kuditipudi",
        "given": "Rohith"
      },
      {
        "family": "Kumar",
        "given": "Ananya"
      },
      {
        "family": "Ladhak",
        "given": "Faisal"
      },
      {
        "family": "Lee",
        "given": "Mina"
      },
      {
        "family": "Lee",
        "given": "Tony"
      },
      {
        "family": "Leskovec",
        "given": "Jure"
      },
      {
        "family": "Levent",
        "given": "Isabelle"
      },
      {
        "family": "Li",
        "given": "Xiang Lisa"
      },
      {
        "family": "Li",
        "given": "Xuechen"
      },
      {
        "family": "Ma",
        "given": "Tengyu"
      },
      {
        "family": "Malik",
        "given": "Ali"
      },
      {
        "family": "Manning",
        "given": "Christopher D."
      },
      {
        "family": "Mirchandani",
        "given": "Suvir"
      },
      {
        "family": "Mitchell",
        "given": "Eric"
      },
      {
        "family": "Munyikwa",
        "given": "Zanele"
      },
      {
        "family": "Nair",
        "given": "Suraj"
      },
      {
        "family": "Narayan",
        "given": "Avanika"
      },
      {
        "family": "Narayanan",
        "given": "Deepak"
      },
      {
        "family": "Newman",
        "given": "Ben"
      },
      {
        "family": "Nie",
        "given": "Allen"
      },
      {
        "family": "Niebles",
        "given": "Juan Carlos"
      },
      {
        "family": "Nilforoshan",
        "given": "Hamed"
      },
      {
        "family": "Nyarko",
        "given": "Julian"
      },
      {
        "family": "Ogut",
        "given": "Giray"
      },
      {
        "family": "Orr",
        "given": "Laurel"
      },
      {
        "family": "Papadimitriou",
        "given": "Isabel"
      },
      {
        "family": "Park",
        "given": "Joon Sung"
      },
      {
        "family": "Piech",
        "given": "Chris"
      },
      {
        "family": "Portelance",
        "given": "Eva"
      },
      {
        "family": "Potts",
        "given": "Christopher"
      },
      {
        "family": "Raghunathan",
        "given": "Aditi"
      },
      {
        "family": "Reich",
        "given": "Rob"
      },
      {
        "family": "Ren",
        "given": "Hongyu"
      },
      {
        "family": "Rong",
        "given": "Frieda"
      },
      {
        "family": "Roohani",
        "given": "Yusuf"
      },
      {
        "family": "Ruiz",
        "given": "Camilo"
      },
      {
        "family": "Ryan",
        "given": "Jack"
      },
      {
        "family": "Ré",
        "given": "Christopher"
      },
      {
        "family": "Sadigh",
        "given": "Dorsa"
      },
      {
        "family": "Sagawa",
        "given": "Shiori"
      },
      {
        "family": "Santhanam",
        "given": "Keshav"
      },
      {
        "family": "Shih",
        "given": "Andy"
      },
      {
        "family": "Srinivasan",
        "given": "Krishnan"
      },
      {
        "family": "Tamkin",
        "given": "Alex"
      },
      {
        "family": "Taori",
        "given": "Rohan"
      },
      {
        "family": "Thomas",
        "given": "Armin W."
      },
      {
        "family": "Tramèr",
        "given": "Florian"
      },
      {
        "family": "Wang",
        "given": "Rose E."
      },
      {
        "family": "Wang",
        "given": "William"
      },
      {
        "family": "Wu",
        "given": "Bohan"
      },
      {
        "family": "Wu",
        "given": "Jiajun"
      },
      {
        "family": "Wu",
        "given": "Yuhuai"
      },
      {
        "family": "Xie",
        "given": "Sang Michael"
      },
      {
        "family": "Yasunaga",
        "given": "Michihiro"
      },
      {
        "family": "You",
        "given": "Jiaxuan"
      },
      {
        "family": "Zaharia",
        "given": "Matei"
      },
      {
        "family": "Zhang",
        "given": "Michael"
      },
      {
        "family": "Zhang",
        "given": "Tianyi"
      },
      {
        "family": "Zhang",
        "given": "Xikun"
      },
      {
        "family": "Zhang",
        "given": "Yuhui"
      },
      {
        "family": "Zheng",
        "given": "Lucia"
      },
      {
        "family": "Zhou",
        "given": "Kaitlyn"
      },
      {
        "family": "Liang",
        "given": "Percy"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
    "DOI": "10.48550/arxiv.2108.07258",
    "publisher": "arXiv",
    "title": "On the Opportunities and Risks of Foundation Models",
    "URL": "https://doi.org/hw3v",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2108.07258"
  },
  {
    "type": "article",
    "id": "grNza1Og",
    "categories": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Ben"
      },
      {
        "family": "Ellington",
        "given": "Caleb"
      },
      {
        "family": "Aragam",
        "given": "Bryon"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      },
      {
        "family": "Kellis",
        "given": "Manolis"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "abstract": "Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs) identify context-dependent relationships between variables, but the non-convexity induced by the acyclicity requirement makes it difficult to share information between context-specific estimators (e.g. with graph generator functions). For this reason, existing methods for inferring context-specific Bayesian networks have favored breaking datasets into subsamples, limiting statistical power and resolution, and preventing the use of multidimensional and latent contexts. To overcome this challenge, we propose NOTEARS-optimized Mixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian networks as the output of a function which learns to mix archetypal networks according to sample context. The archetypal networks are estimated jointly with the context-specific networks and do not require any prior knowledge. We encode the acyclicity constraint as a smooth regularization loss which is back-propagated to the mixing function; in this way, NOTMAD shares information between context-specific acyclic graphs, enabling the estimation of Bayesian network structures and parameters at even single-sample resolution. We demonstrate the utility of NOTMAD and sample-specific network inference through analysis and experiments, including patient-specific gene expression networks which correspond to morphological variation in cancer.",
    "DOI": "10.48550/arxiv.2111.01104",
    "publisher": "arXiv",
    "title": "NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and Parameters",
    "URL": "https://doi.org/gt68jc",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2111.01104"
  },
  {
    "type": "article",
    "id": "k6r0UwSv",
    "categories": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Suriyakumar",
        "given": "Vinith M."
      },
      {
        "family": "Ghassemi",
        "given": "Marzyeh"
      },
      {
        "family": "Ustun",
        "given": "Berk"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "Machine learning models are often personalized with categorical attributes that are protected, sensitive, self-reported, or costly to acquire. In this work, we show models that are personalized with group attributes can reduce performance at a group level. We propose formal conditions to ensure the \"fair use\" of group attributes in prediction tasks by training one additional model -- i.e., collective preference guarantees to ensure that each group who provides personal data will receive a tailored gain in performance in return. We present sufficient conditions to ensure fair use in empirical risk minimization and characterize failure modes that lead to fair use violations due to standard practices in model development and deployment. We present a comprehensive empirical study of fair use in clinical prediction tasks. Our results demonstrate the prevalence of fair use violations in practice and illustrate simple interventions to mitigate their harm.",
    "DOI": "10.48550/arxiv.2206.02058",
    "publisher": "arXiv",
    "title": "When Personalization Harms: Reconsidering the Use of Group Attributes in Prediction",
    "URL": "https://doi.org/gt68jd",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2206.02058"
  },
  {
    "type": "article",
    "id": "rYveVDKJ",
    "categories": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Hollmann",
        "given": "Noah"
      },
      {
        "family": "Müller",
        "given": "Samuel"
      },
      {
        "family": "Eggensperger",
        "given": "Katharina"
      },
      {
        "family": "Hutter",
        "given": "Frank"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN performs in-context learning (ICL), it learns to make predictions using sequences of labeled examples (x, f(x)) given in the input, without requiring further parameter updates. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to 230$\\times$ speedup. This increases to a 5 700$\\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.",
    "DOI": "10.48550/arxiv.2207.01848",
    "publisher": "arXiv",
    "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second",
    "URL": "https://doi.org/g9t22b",
    "version": "6",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2207.01848"
  },
  {
    "type": "article",
    "id": "R7y5TKp9",
    "categories": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Garg",
        "given": "Shivam"
      },
      {
        "family": "Tsipras",
        "given": "Dimitris"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Valiant",
        "given": "Gregory"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "In-context learning refers to the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To make progress towards understanding in-context learning, we consider the well-defined problem of training a model to in-context learn a function class (e.g., linear functions): that is, given data derived from some functions in the class, can we train a model to in-context learn \"most\" functions from this class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions -- that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift: (i) between the training data of the model and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes -- namely sparse linear functions, two-layer neural networks, and decision trees -- with performance that matches or exceeds task-specific learning algorithms. Our code and models are available at https://github.com/dtsip/in-context-learning .",
    "DOI": "10.48550/arxiv.2208.01066",
    "publisher": "arXiv",
    "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes",
    "URL": "https://doi.org/g9t22c",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2208.01066"
  },
  {
    "type": "article",
    "id": "Xtwwrjzy",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Choi",
        "given": "Kristy"
      },
      {
        "family": "Cundy",
        "given": "Chris"
      },
      {
        "family": "Srivastava",
        "given": "Sanjari"
      },
      {
        "family": "Ermon",
        "given": "Stefano"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "Particularly in low-data regimes, an outstanding challenge in machine learning is developing principled techniques for augmenting our models with suitable priors. This is to encourage them to learn in ways that are compatible with our understanding of the world. But in contrast to generic priors such as shrinkage or sparsity, we draw inspiration from the recent successes of large-scale language models (LMs) to construct task-specific priors distilled from the rich knowledge of LMs. Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata. Empirically, we demonstrate that LMPriors improve model performance in settings where such natural language descriptions are available, and perform well on several tasks that benefit from such prior knowledge, such as feature selection, causal inference, and safe reinforcement learning.",
    "DOI": "10.48550/arxiv.2210.12530",
    "publisher": "arXiv",
    "title": "LMPriors: Pre-Trained Language Models as Task-Specific Priors",
    "URL": "https://doi.org/g9t22d",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2210.12530"
  },
  {
    "type": "article",
    "id": "1AazNaZYl",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Su",
        "given": "Hongjin"
      },
      {
        "family": "Shi",
        "given": "Weijia"
      },
      {
        "family": "Kasai",
        "given": "Jungo"
      },
      {
        "family": "Wang",
        "given": "Yizhong"
      },
      {
        "family": "Hu",
        "given": "Yushi"
      },
      {
        "family": "Ostendorf",
        "given": "Mari"
      },
      {
        "family": "Yih",
        "given": "Wen-tau"
      },
      {
        "family": "Smith",
        "given": "Noah A."
      },
      {
        "family": "Zettlemoyer",
        "given": "Luke"
      },
      {
        "family": "Yu",
        "given": "Tao"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "abstract": "We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions: every text input is embedded together with instructions explaining the use case (e.g., task and domain descriptions). Unlike encoders from prior work that are more specialized, INSTRUCTOR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training. We first annotate instructions for 330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training), ranging from classification and information retrieval to semantic textual similarity and text generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than the previous best model, achieves state-of-the-art performance, with an average improvement of 3.4% compared to the previous best results on the 70 diverse datasets. Our analysis suggests that INSTRUCTOR is robust to changes in instructions, and that instruction finetuning mitigates the challenge of training a single model on diverse datasets. Our model, code, and data are available at https://instructor-embedding.github.io.",
    "DOI": "10.48550/arxiv.2212.09741",
    "publisher": "arXiv",
    "title": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings",
    "URL": "https://doi.org/g9t22f",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2212.09741"
  },
  {
    "type": "article",
    "id": "11RvF4F7q",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "McInerney",
        "given": "Denis Jered"
      },
      {
        "family": "Young",
        "given": "Geoffrey"
      },
      {
        "family": "van de Meent",
        "given": "Jan-Willem"
      },
      {
        "family": "Wallace",
        "given": "Byron C."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "We propose CHiLL (Crafting High-Level Latents), an approach for natural-language specification of features for linear models. CHiLL prompts LLMs with expert-crafted queries to generate interpretable features from health records. The resulting noisy labels are then used to train a simple linear classifier. Generating features based on queries to an LLM can empower physicians to use their domain expertise to craft features that are clinically meaningful for a downstream task of interest, without having to manually extract these from raw EHR. We are motivated by a real-world risk prediction task, but as a reproducible proxy, we use MIMIC-III and MIMIC-CXR data and standard predictive tasks (e.g., 30-day readmission) to evaluate this approach. We find that linear models using automatically extracted features are comparably performant to models using reference features, and provide greater interpretability than linear models using \"Bag-of-Words\" features. We verify that learned feature weights align well with clinical expectations.",
    "DOI": "10.48550/arxiv.2302.12343",
    "publisher": "arXiv",
    "title": "CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models",
    "URL": "https://doi.org/g9t22g",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2302.12343"
  },
  {
    "type": "article",
    "id": "17lpGtuH5",
    "categories": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "OpenAI"
      },
      {
        "family": "Achiam",
        "given": "Josh"
      },
      {
        "family": "Adler",
        "given": "Steven"
      },
      {
        "family": "Agarwal",
        "given": "Sandhini"
      },
      {
        "family": "Ahmad",
        "given": "Lama"
      },
      {
        "family": "Akkaya",
        "given": "Ilge"
      },
      {
        "family": "Aleman",
        "given": "Florencia Leoni"
      },
      {
        "family": "Almeida",
        "given": "Diogo"
      },
      {
        "family": "Altenschmidt",
        "given": "Janko"
      },
      {
        "family": "Altman",
        "given": "Sam"
      },
      {
        "family": "Anadkat",
        "given": "Shyamal"
      },
      {
        "family": "Avila",
        "given": "Red"
      },
      {
        "family": "Babuschkin",
        "given": "Igor"
      },
      {
        "family": "Balaji",
        "given": "Suchir"
      },
      {
        "family": "Balcom",
        "given": "Valerie"
      },
      {
        "family": "Baltescu",
        "given": "Paul"
      },
      {
        "family": "Bao",
        "given": "Haiming"
      },
      {
        "family": "Bavarian",
        "given": "Mohammad"
      },
      {
        "family": "Belgum",
        "given": "Jeff"
      },
      {
        "family": "Bello",
        "given": "Irwan"
      },
      {
        "family": "Berdine",
        "given": "Jake"
      },
      {
        "family": "Bernadett-Shapiro",
        "given": "Gabriel"
      },
      {
        "family": "Berner",
        "given": "Christopher"
      },
      {
        "family": "Bogdonoff",
        "given": "Lenny"
      },
      {
        "family": "Boiko",
        "given": "Oleg"
      },
      {
        "family": "Boyd",
        "given": "Madelaine"
      },
      {
        "family": "Brakman",
        "given": "Anna-Luisa"
      },
      {
        "family": "Brockman",
        "given": "Greg"
      },
      {
        "family": "Brooks",
        "given": "Tim"
      },
      {
        "family": "Brundage",
        "given": "Miles"
      },
      {
        "family": "Button",
        "given": "Kevin"
      },
      {
        "family": "Cai",
        "given": "Trevor"
      },
      {
        "family": "Campbell",
        "given": "Rosie"
      },
      {
        "family": "Cann",
        "given": "Andrew"
      },
      {
        "family": "Carey",
        "given": "Brittany"
      },
      {
        "family": "Carlson",
        "given": "Chelsea"
      },
      {
        "family": "Carmichael",
        "given": "Rory"
      },
      {
        "family": "Chan",
        "given": "Brooke"
      },
      {
        "family": "Chang",
        "given": "Che"
      },
      {
        "family": "Chantzis",
        "given": "Fotis"
      },
      {
        "family": "Chen",
        "given": "Derek"
      },
      {
        "family": "Chen",
        "given": "Sully"
      },
      {
        "family": "Chen",
        "given": "Ruby"
      },
      {
        "family": "Chen",
        "given": "Jason"
      },
      {
        "family": "Chen",
        "given": "Mark"
      },
      {
        "family": "Chess",
        "given": "Ben"
      },
      {
        "family": "Cho",
        "given": "Chester"
      },
      {
        "family": "Chu",
        "given": "Casey"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Cummings",
        "given": "Dave"
      },
      {
        "family": "Currier",
        "given": "Jeremiah"
      },
      {
        "family": "Dai",
        "given": "Yunxing"
      },
      {
        "family": "Decareaux",
        "given": "Cory"
      },
      {
        "family": "Degry",
        "given": "Thomas"
      },
      {
        "family": "Deutsch",
        "given": "Noah"
      },
      {
        "family": "Deville",
        "given": "Damien"
      },
      {
        "family": "Dhar",
        "given": "Arka"
      },
      {
        "family": "Dohan",
        "given": "David"
      },
      {
        "family": "Dowling",
        "given": "Steve"
      },
      {
        "family": "Dunning",
        "given": "Sheila"
      },
      {
        "family": "Ecoffet",
        "given": "Adrien"
      },
      {
        "family": "Eleti",
        "given": "Atty"
      },
      {
        "family": "Eloundou",
        "given": "Tyna"
      },
      {
        "family": "Farhi",
        "given": "David"
      },
      {
        "family": "Fedus",
        "given": "Liam"
      },
      {
        "family": "Felix",
        "given": "Niko"
      },
      {
        "family": "Fishman",
        "given": "Simón Posada"
      },
      {
        "family": "Forte",
        "given": "Juston"
      },
      {
        "family": "Fulford",
        "given": "Isabella"
      },
      {
        "family": "Gao",
        "given": "Leo"
      },
      {
        "family": "Georges",
        "given": "Elie"
      },
      {
        "family": "Gibson",
        "given": "Christian"
      },
      {
        "family": "Goel",
        "given": "Vik"
      },
      {
        "family": "Gogineni",
        "given": "Tarun"
      },
      {
        "family": "Goh",
        "given": "Gabriel"
      },
      {
        "family": "Gontijo-Lopes",
        "given": "Rapha"
      },
      {
        "family": "Gordon",
        "given": "Jonathan"
      },
      {
        "family": "Grafstein",
        "given": "Morgan"
      },
      {
        "family": "Gray",
        "given": "Scott"
      },
      {
        "family": "Greene",
        "given": "Ryan"
      },
      {
        "family": "Gross",
        "given": "Joshua"
      },
      {
        "family": "Gu",
        "given": "Shixiang Shane"
      },
      {
        "family": "Guo",
        "given": "Yufei"
      },
      {
        "family": "Hallacy",
        "given": "Chris"
      },
      {
        "family": "Han",
        "given": "Jesse"
      },
      {
        "family": "Harris",
        "given": "Jeff"
      },
      {
        "family": "He",
        "given": "Yuchen"
      },
      {
        "family": "Heaton",
        "given": "Mike"
      },
      {
        "family": "Heidecke",
        "given": "Johannes"
      },
      {
        "family": "Hesse",
        "given": "Chris"
      },
      {
        "family": "Hickey",
        "given": "Alan"
      },
      {
        "family": "Hickey",
        "given": "Wade"
      },
      {
        "family": "Hoeschele",
        "given": "Peter"
      },
      {
        "family": "Houghton",
        "given": "Brandon"
      },
      {
        "family": "Hsu",
        "given": "Kenny"
      },
      {
        "family": "Hu",
        "given": "Shengli"
      },
      {
        "family": "Hu",
        "given": "Xin"
      },
      {
        "family": "Huizinga",
        "given": "Joost"
      },
      {
        "family": "Jain",
        "given": "Shantanu"
      },
      {
        "family": "Jain",
        "given": "Shawn"
      },
      {
        "family": "Jang",
        "given": "Joanne"
      },
      {
        "family": "Jiang",
        "given": "Angela"
      },
      {
        "family": "Jiang",
        "given": "Roger"
      },
      {
        "family": "Jin",
        "given": "Haozhun"
      },
      {
        "family": "Jin",
        "given": "Denny"
      },
      {
        "family": "Jomoto",
        "given": "Shino"
      },
      {
        "family": "Jonn",
        "given": "Billie"
      },
      {
        "family": "Jun",
        "given": "Heewoo"
      },
      {
        "family": "Kaftan",
        "given": "Tomer"
      },
      {
        "family": "Kaiser",
        "given": "Łukasz"
      },
      {
        "family": "Kamali",
        "given": "Ali"
      },
      {
        "family": "Kanitscheider",
        "given": "Ingmar"
      },
      {
        "family": "Keskar",
        "given": "Nitish Shirish"
      },
      {
        "family": "Khan",
        "given": "Tabarak"
      },
      {
        "family": "Kilpatrick",
        "given": "Logan"
      },
      {
        "family": "Kim",
        "given": "Jong Wook"
      },
      {
        "family": "Kim",
        "given": "Christina"
      },
      {
        "family": "Kim",
        "given": "Yongjik"
      },
      {
        "family": "Kirchner",
        "given": "Jan Hendrik"
      },
      {
        "family": "Kiros",
        "given": "Jamie"
      },
      {
        "family": "Knight",
        "given": "Matt"
      },
      {
        "family": "Kokotajlo",
        "given": "Daniel"
      },
      {
        "family": "Kondraciuk",
        "given": "Łukasz"
      },
      {
        "family": "Kondrich",
        "given": "Andrew"
      },
      {
        "family": "Konstantinidis",
        "given": "Aris"
      },
      {
        "family": "Kosic",
        "given": "Kyle"
      },
      {
        "family": "Krueger",
        "given": "Gretchen"
      },
      {
        "family": "Kuo",
        "given": "Vishal"
      },
      {
        "family": "Lampe",
        "given": "Michael"
      },
      {
        "family": "Lan",
        "given": "Ikai"
      },
      {
        "family": "Lee",
        "given": "Teddy"
      },
      {
        "family": "Leike",
        "given": "Jan"
      },
      {
        "family": "Leung",
        "given": "Jade"
      },
      {
        "family": "Levy",
        "given": "Daniel"
      },
      {
        "family": "Li",
        "given": "Chak Ming"
      },
      {
        "family": "Lim",
        "given": "Rachel"
      },
      {
        "family": "Lin",
        "given": "Molly"
      },
      {
        "family": "Lin",
        "given": "Stephanie"
      },
      {
        "family": "Litwin",
        "given": "Mateusz"
      },
      {
        "family": "Lopez",
        "given": "Theresa"
      },
      {
        "family": "Lowe",
        "given": "Ryan"
      },
      {
        "family": "Lue",
        "given": "Patricia"
      },
      {
        "family": "Makanju",
        "given": "Anna"
      },
      {
        "family": "Malfacini",
        "given": "Kim"
      },
      {
        "family": "Manning",
        "given": "Sam"
      },
      {
        "family": "Markov",
        "given": "Todor"
      },
      {
        "family": "Markovski",
        "given": "Yaniv"
      },
      {
        "family": "Martin",
        "given": "Bianca"
      },
      {
        "family": "Mayer",
        "given": "Katie"
      },
      {
        "family": "Mayne",
        "given": "Andrew"
      },
      {
        "family": "McGrew",
        "given": "Bob"
      },
      {
        "family": "McKinney",
        "given": "Scott Mayer"
      },
      {
        "family": "McLeavey",
        "given": "Christine"
      },
      {
        "family": "McMillan",
        "given": "Paul"
      },
      {
        "family": "McNeil",
        "given": "Jake"
      },
      {
        "family": "Medina",
        "given": "David"
      },
      {
        "family": "Mehta",
        "given": "Aalok"
      },
      {
        "family": "Menick",
        "given": "Jacob"
      },
      {
        "family": "Metz",
        "given": "Luke"
      },
      {
        "family": "Mishchenko",
        "given": "Andrey"
      },
      {
        "family": "Mishkin",
        "given": "Pamela"
      },
      {
        "family": "Monaco",
        "given": "Vinnie"
      },
      {
        "family": "Morikawa",
        "given": "Evan"
      },
      {
        "family": "Mossing",
        "given": "Daniel"
      },
      {
        "family": "Mu",
        "given": "Tong"
      },
      {
        "family": "Murati",
        "given": "Mira"
      },
      {
        "family": "Murk",
        "given": "Oleg"
      },
      {
        "family": "Mély",
        "given": "David"
      },
      {
        "family": "Nair",
        "given": "Ashvin"
      },
      {
        "family": "Nakano",
        "given": "Reiichiro"
      },
      {
        "family": "Nayak",
        "given": "Rajeev"
      },
      {
        "family": "Neelakantan",
        "given": "Arvind"
      },
      {
        "family": "Ngo",
        "given": "Richard"
      },
      {
        "family": "Noh",
        "given": "Hyeonwoo"
      },
      {
        "family": "Ouyang",
        "given": "Long"
      },
      {
        "family": "O'Keefe",
        "given": "Cullen"
      },
      {
        "family": "Pachocki",
        "given": "Jakub"
      },
      {
        "family": "Paino",
        "given": "Alex"
      },
      {
        "family": "Palermo",
        "given": "Joe"
      },
      {
        "family": "Pantuliano",
        "given": "Ashley"
      },
      {
        "family": "Parascandolo",
        "given": "Giambattista"
      },
      {
        "family": "Parish",
        "given": "Joel"
      },
      {
        "family": "Parparita",
        "given": "Emy"
      },
      {
        "family": "Passos",
        "given": "Alex"
      },
      {
        "family": "Pavlov",
        "given": "Mikhail"
      },
      {
        "family": "Peng",
        "given": "Andrew"
      },
      {
        "family": "Perelman",
        "given": "Adam"
      },
      {
        "family": "Peres",
        "given": "Filipe de Avila Belbute"
      },
      {
        "family": "Petrov",
        "given": "Michael"
      },
      {
        "family": "Pinto",
        "given": "Henrique Ponde de Oliveira"
      },
      {
        "family": "Michael"
      },
      {
        "literal": "Pokorny"
      },
      {
        "family": "Pokrass",
        "given": "Michelle"
      },
      {
        "family": "Pong",
        "given": "Vitchyr H."
      },
      {
        "family": "Powell",
        "given": "Tolly"
      },
      {
        "family": "Power",
        "given": "Alethea"
      },
      {
        "family": "Power",
        "given": "Boris"
      },
      {
        "family": "Proehl",
        "given": "Elizabeth"
      },
      {
        "family": "Puri",
        "given": "Raul"
      },
      {
        "family": "Radford",
        "given": "Alec"
      },
      {
        "family": "Rae",
        "given": "Jack"
      },
      {
        "family": "Ramesh",
        "given": "Aditya"
      },
      {
        "family": "Raymond",
        "given": "Cameron"
      },
      {
        "family": "Real",
        "given": "Francis"
      },
      {
        "family": "Rimbach",
        "given": "Kendra"
      },
      {
        "family": "Ross",
        "given": "Carl"
      },
      {
        "family": "Rotsted",
        "given": "Bob"
      },
      {
        "family": "Roussez",
        "given": "Henri"
      },
      {
        "family": "Ryder",
        "given": "Nick"
      },
      {
        "family": "Saltarelli",
        "given": "Mario"
      },
      {
        "family": "Sanders",
        "given": "Ted"
      },
      {
        "family": "Santurkar",
        "given": "Shibani"
      },
      {
        "family": "Sastry",
        "given": "Girish"
      },
      {
        "family": "Schmidt",
        "given": "Heather"
      },
      {
        "family": "Schnurr",
        "given": "David"
      },
      {
        "family": "Schulman",
        "given": "John"
      },
      {
        "family": "Selsam",
        "given": "Daniel"
      },
      {
        "family": "Sheppard",
        "given": "Kyla"
      },
      {
        "family": "Sherbakov",
        "given": "Toki"
      },
      {
        "family": "Shieh",
        "given": "Jessica"
      },
      {
        "family": "Shoker",
        "given": "Sarah"
      },
      {
        "family": "Shyam",
        "given": "Pranav"
      },
      {
        "family": "Sidor",
        "given": "Szymon"
      },
      {
        "family": "Sigler",
        "given": "Eric"
      },
      {
        "family": "Simens",
        "given": "Maddie"
      },
      {
        "family": "Sitkin",
        "given": "Jordan"
      },
      {
        "family": "Slama",
        "given": "Katarina"
      },
      {
        "family": "Sohl",
        "given": "Ian"
      },
      {
        "family": "Sokolowsky",
        "given": "Benjamin"
      },
      {
        "family": "Song",
        "given": "Yang"
      },
      {
        "family": "Staudacher",
        "given": "Natalie"
      },
      {
        "family": "Such",
        "given": "Felipe Petroski"
      },
      {
        "family": "Summers",
        "given": "Natalie"
      },
      {
        "family": "Sutskever",
        "given": "Ilya"
      },
      {
        "family": "Tang",
        "given": "Jie"
      },
      {
        "family": "Tezak",
        "given": "Nikolas"
      },
      {
        "family": "Thompson",
        "given": "Madeleine B."
      },
      {
        "family": "Tillet",
        "given": "Phil"
      },
      {
        "family": "Tootoonchian",
        "given": "Amin"
      },
      {
        "family": "Tseng",
        "given": "Elizabeth"
      },
      {
        "family": "Tuggle",
        "given": "Preston"
      },
      {
        "family": "Turley",
        "given": "Nick"
      },
      {
        "family": "Tworek",
        "given": "Jerry"
      },
      {
        "family": "Uribe",
        "given": "Juan Felipe Cerón"
      },
      {
        "family": "Vallone",
        "given": "Andrea"
      },
      {
        "family": "Vijayvergiya",
        "given": "Arun"
      },
      {
        "family": "Voss",
        "given": "Chelsea"
      },
      {
        "family": "Wainwright",
        "given": "Carroll"
      },
      {
        "family": "Wang",
        "given": "Justin Jay"
      },
      {
        "family": "Wang",
        "given": "Alvin"
      },
      {
        "family": "Wang",
        "given": "Ben"
      },
      {
        "family": "Ward",
        "given": "Jonathan"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Weinmann",
        "given": "CJ"
      },
      {
        "family": "Welihinda",
        "given": "Akila"
      },
      {
        "family": "Welinder",
        "given": "Peter"
      },
      {
        "family": "Weng",
        "given": "Jiayi"
      },
      {
        "family": "Weng",
        "given": "Lilian"
      },
      {
        "family": "Wiethoff",
        "given": "Matt"
      },
      {
        "family": "Willner",
        "given": "Dave"
      },
      {
        "family": "Winter",
        "given": "Clemens"
      },
      {
        "family": "Wolrich",
        "given": "Samuel"
      },
      {
        "family": "Wong",
        "given": "Hannah"
      },
      {
        "family": "Workman",
        "given": "Lauren"
      },
      {
        "family": "Wu",
        "given": "Sherwin"
      },
      {
        "family": "Wu",
        "given": "Jeff"
      },
      {
        "family": "Wu",
        "given": "Michael"
      },
      {
        "family": "Xiao",
        "given": "Kai"
      },
      {
        "family": "Xu",
        "given": "Tao"
      },
      {
        "family": "Yoo",
        "given": "Sarah"
      },
      {
        "family": "Yu",
        "given": "Kevin"
      },
      {
        "family": "Yuan",
        "given": "Qiming"
      },
      {
        "family": "Zaremba",
        "given": "Wojciech"
      },
      {
        "family": "Zellers",
        "given": "Rowan"
      },
      {
        "family": "Zhang",
        "given": "Chong"
      },
      {
        "family": "Zhang",
        "given": "Marvin"
      },
      {
        "family": "Zhao",
        "given": "Shengjia"
      },
      {
        "family": "Zheng",
        "given": "Tianhao"
      },
      {
        "family": "Zhuang",
        "given": "Juntang"
      },
      {
        "family": "Zhuk",
        "given": "William"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
    "DOI": "10.48550/arxiv.2303.08774",
    "publisher": "arXiv",
    "title": "GPT-4 Technical Report",
    "URL": "https://doi.org/grx4cb",
    "version": "6",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2303.08774"
  },
  {
    "type": "article",
    "id": "10hcHcmAG",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Patel",
        "given": "Ajay"
      },
      {
        "family": "Rao",
        "given": "Delip"
      },
      {
        "family": "Kothary",
        "given": "Ansh"
      },
      {
        "family": "McKeown",
        "given": "Kathleen"
      },
      {
        "family": "Callison-Burch",
        "given": "Chris"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Style representation learning builds content-independent representations of author style in text. Stylometry, the analysis of style in text, is often performed by expert forensic linguists and no large dataset of stylometric annotations exists for training. Current style representation learning uses neural methods to disentangle style from content to create style vectors, however, these approaches result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to create a synthetic dataset and train human-interpretable style representations we call LISA embeddings. We release our synthetic stylometry dataset and our interpretable style models as resources.",
    "DOI": "10.48550/arxiv.2305.12696",
    "publisher": "arXiv",
    "title": "Learning Interpretable Style Embeddings via Prompting LLMs",
    "URL": "https://doi.org/g9t22h",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2305.12696"
  },
  {
    "type": "article",
    "id": "zWwbz3cX",
    "categories": [
      "Computation and Language (cs.CL)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Shen",
        "given": "Sheng"
      },
      {
        "family": "Hou",
        "given": "Le"
      },
      {
        "family": "Zhou",
        "given": "Yanqi"
      },
      {
        "family": "Du",
        "given": "Nan"
      },
      {
        "family": "Longpre",
        "given": "Shayne"
      },
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Chung",
        "given": "Hyung Won"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      },
      {
        "family": "Fedus",
        "given": "William"
      },
      {
        "family": "Chen",
        "given": "Xinyun"
      },
      {
        "family": "Vu",
        "given": "Tu"
      },
      {
        "family": "Wu",
        "given": "Yuexin"
      },
      {
        "family": "Chen",
        "given": "Wuyang"
      },
      {
        "family": "Webson",
        "given": "Albert"
      },
      {
        "family": "Li",
        "given": "Yunxuan"
      },
      {
        "family": "Zhao",
        "given": "Vincent"
      },
      {
        "family": "Yu",
        "given": "Hongkun"
      },
      {
        "family": "Keutzer",
        "given": "Kurt"
      },
      {
        "family": "Darrell",
        "given": "Trevor"
      },
      {
        "family": "Zhou",
        "given": "Denny"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Sparse Mixture-of-Experts (MoE) is a neural architecture design that can be utilized to add learnable parameters to Large Language Models (LLMs) without increasing inference cost. Instruction tuning is a technique for training LLMs to follow instructions. We advocate combining these two approaches, as we find that MoE models benefit more from instruction tuning than dense models. In particular, we conduct empirical studies across three experimental setups: (i) Direct finetuning on individual downstream tasks devoid of instruction tuning; (ii) Instructiontuning followed by in-context few-shot or zero-shot generalization on downstream tasks; and (iii) Instruction tuning supplemented by further finetuning on individual downstream tasks. In the first scenario, MoE models overall underperform dense models of identical computational capacity. This narrative, however, dramatically changes with the introduction of instruction tuning (second and third scenario), used independently or in conjunction with task-specific finetuning. Our most powerful model, FLAN-MOE-32B, surpasses the performance of FLAN-PALM-62B on four benchmark tasks, while using only a third of the FLOPs. The advancements embodied byFLAN-MOE inspire a reevaluation of the design principles of large-scale, high-performance language models in the framework of task-agnostic learning.",
    "DOI": "10.48550/arxiv.2305.14705",
    "publisher": "arXiv",
    "title": "Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models",
    "URL": "https://doi.org/g9t22j",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2305.14705"
  },
  {
    "type": "article",
    "id": "nYipTPML",
    "categories": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Deuschel",
        "given": "Jannik"
      },
      {
        "family": "Ellington",
        "given": "Caleb N."
      },
      {
        "family": "Luo",
        "given": "Yingtao"
      },
      {
        "family": "Lengerich",
        "given": "Benjamin J."
      },
      {
        "family": "Friederich",
        "given": "Pascal"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models force a tradeoff between accuracy and interpretability, limiting data-driven interpretations of human decision-making processes. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically under different contexts. Thus, we develop Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem, where each context poses a unique task and complex decision policies can be constructed piece-wise from many simple context-specific policies. CPR models each context-specific policy as a linear map, and generates new policy models $\\textit{on-demand}$ as contexts are updated with new observations. We provide two flavors of the CPR framework: one focusing on exact local interpretability, and one retaining full global interpretability. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement, CPR closes the accuracy gap between interpretable and black-box methods, allowing high-resolution exploration and analysis of context-specific decision models.",
    "DOI": "10.48550/arxiv.2310.07918",
    "publisher": "arXiv",
    "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning",
    "URL": "https://doi.org/gt68jf",
    "version": "4",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2310.07918"
  },
  {
    "type": "article",
    "id": "HYsEq2UQ",
    "categories": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Lengerich",
        "given": "Benjamin"
      },
      {
        "family": "Ellington",
        "given": "Caleb N."
      },
      {
        "family": "Rubbi",
        "given": "Andrea"
      },
      {
        "family": "Kellis",
        "given": "Manolis"
      },
      {
        "family": "Xing",
        "given": "Eric P."
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "We examine Contextualized Machine Learning (ML), a paradigm for learning heterogeneous and context-dependent effects. Contextualized ML estimates heterogeneous functions by applying deep learning to the meta-relationship between contextual information and context-specific parametric models. This is a form of varying-coefficient modeling that unifies existing frameworks including cluster analysis and cohort modeling by introducing two reusable concepts: a context encoder which translates sample context into model parameters, and sample-specific model which operates on sample predictors. We review the process of developing contextualized models, nonparametric inference from contextualized models, and identifiability conditions of contextualized models. Finally, we present the open-source PyTorch package ContextualizedML.",
    "DOI": "10.48550/arxiv.2310.11340",
    "publisher": "arXiv",
    "title": "Contextualized Machine Learning",
    "URL": "https://doi.org/gt68jg",
    "version": "1",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2310.11340"
  },
  {
    "type": "article",
    "id": "9S6tI5yv",
    "categories": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Sristi",
        "given": "Ram Dyuthi"
      },
      {
        "family": "Lindenbaum",
        "given": "Ofir"
      },
      {
        "family": "Lifshitz",
        "given": "Shira"
      },
      {
        "family": "Lavzin",
        "given": "Maria"
      },
      {
        "family": "Schiller",
        "given": "Jackie"
      },
      {
        "family": "Mishne",
        "given": "Gal"
      },
      {
        "family": "Benisty",
        "given": "Hadas"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "abstract": "Feature selection is a crucial tool in machine learning and is widely applied across various scientific disciplines. Traditional supervised methods generally identify a universal set of informative features for the entire population. However, feature relevance often varies with context, while the context itself may not directly affect the outcome variable. Here, we propose a novel architecture for contextual feature selection where the subset of selected features is conditioned on the value of context variables. Our new approach, Conditional Stochastic Gates (c-STG), models the importance of features using conditional Bernoulli variables whose parameters are predicted based on contextual variables. We introduce a hypernetwork that maps context variables to feature selection parameters to learn the context-dependent gates along with a prediction model. We further present a theoretical analysis of our model, indicating that it can improve performance and flexibility over population-level methods in complex feature selection settings. Finally, we conduct an extensive benchmark using simulated and real-world datasets across multiple domains demonstrating that c-STG can lead to improved feature selection capabilities while enhancing prediction accuracy and interpretability.",
    "DOI": "10.48550/arxiv.2312.14254",
    "publisher": "arXiv",
    "title": "Contextual Feature Selection with Conditional Stochastic Gates",
    "URL": "https://doi.org/gt68jh",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2312.14254"
  },
  {
    "type": "article",
    "id": "yWg7tQr1",
    "categories": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Grattafiori",
        "given": "Aaron"
      },
      {
        "family": "Dubey",
        "given": "Abhimanyu"
      },
      {
        "family": "Jauhri",
        "given": "Abhinav"
      },
      {
        "family": "Pandey",
        "given": "Abhinav"
      },
      {
        "family": "Kadian",
        "given": "Abhishek"
      },
      {
        "family": "Al-Dahle",
        "given": "Ahmad"
      },
      {
        "family": "Letman",
        "given": "Aiesha"
      },
      {
        "family": "Mathur",
        "given": "Akhil"
      },
      {
        "family": "Schelten",
        "given": "Alan"
      },
      {
        "family": "Vaughan",
        "given": "Alex"
      },
      {
        "family": "Yang",
        "given": "Amy"
      },
      {
        "family": "Fan",
        "given": "Angela"
      },
      {
        "family": "Goyal",
        "given": "Anirudh"
      },
      {
        "family": "Hartshorn",
        "given": "Anthony"
      },
      {
        "family": "Yang",
        "given": "Aobo"
      },
      {
        "family": "Mitra",
        "given": "Archi"
      },
      {
        "family": "Sravankumar",
        "given": "Archie"
      },
      {
        "family": "Korenev",
        "given": "Artem"
      },
      {
        "family": "Hinsvark",
        "given": "Arthur"
      },
      {
        "family": "Rao",
        "given": "Arun"
      },
      {
        "family": "Zhang",
        "given": "Aston"
      },
      {
        "family": "Rodriguez",
        "given": "Aurelien"
      },
      {
        "family": "Gregerson",
        "given": "Austen"
      },
      {
        "family": "Spataru",
        "given": "Ava"
      },
      {
        "family": "Roziere",
        "given": "Baptiste"
      },
      {
        "family": "Biron",
        "given": "Bethany"
      },
      {
        "family": "Tang",
        "given": "Binh"
      },
      {
        "family": "Chern",
        "given": "Bobbie"
      },
      {
        "family": "Caucheteux",
        "given": "Charlotte"
      },
      {
        "family": "Nayak",
        "given": "Chaya"
      },
      {
        "family": "Bi",
        "given": "Chloe"
      },
      {
        "family": "Marra",
        "given": "Chris"
      },
      {
        "family": "McConnell",
        "given": "Chris"
      },
      {
        "family": "Keller",
        "given": "Christian"
      },
      {
        "family": "Touret",
        "given": "Christophe"
      },
      {
        "family": "Wu",
        "given": "Chunyang"
      },
      {
        "family": "Wong",
        "given": "Corinne"
      },
      {
        "family": "Ferrer",
        "given": "Cristian Canton"
      },
      {
        "family": "Nikolaidis",
        "given": "Cyrus"
      },
      {
        "family": "Allonsius",
        "given": "Damien"
      },
      {
        "family": "Song",
        "given": "Daniel"
      },
      {
        "family": "Pintz",
        "given": "Danielle"
      },
      {
        "family": "Livshits",
        "given": "Danny"
      },
      {
        "family": "Wyatt",
        "given": "Danny"
      },
      {
        "family": "Esiobu",
        "given": "David"
      },
      {
        "family": "Choudhary",
        "given": "Dhruv"
      },
      {
        "family": "Mahajan",
        "given": "Dhruv"
      },
      {
        "family": "Garcia-Olano",
        "given": "Diego"
      },
      {
        "family": "Perino",
        "given": "Diego"
      },
      {
        "family": "Hupkes",
        "given": "Dieuwke"
      },
      {
        "family": "Lakomkin",
        "given": "Egor"
      },
      {
        "family": "AlBadawy",
        "given": "Ehab"
      },
      {
        "family": "Lobanova",
        "given": "Elina"
      },
      {
        "family": "Dinan",
        "given": "Emily"
      },
      {
        "family": "Smith",
        "given": "Eric Michael"
      },
      {
        "family": "Radenovic",
        "given": "Filip"
      },
      {
        "family": "Guzmán",
        "given": "Francisco"
      },
      {
        "family": "Zhang",
        "given": "Frank"
      },
      {
        "family": "Synnaeve",
        "given": "Gabriel"
      },
      {
        "family": "Lee",
        "given": "Gabrielle"
      },
      {
        "family": "Anderson",
        "given": "Georgia Lewis"
      },
      {
        "family": "Thattai",
        "given": "Govind"
      },
      {
        "family": "Nail",
        "given": "Graeme"
      },
      {
        "family": "Mialon",
        "given": "Gregoire"
      },
      {
        "family": "Pang",
        "given": "Guan"
      },
      {
        "family": "Cucurell",
        "given": "Guillem"
      },
      {
        "family": "Nguyen",
        "given": "Hailey"
      },
      {
        "family": "Korevaar",
        "given": "Hannah"
      },
      {
        "family": "Xu",
        "given": "Hu"
      },
      {
        "family": "Touvron",
        "given": "Hugo"
      },
      {
        "family": "Zarov",
        "given": "Iliyan"
      },
      {
        "family": "Ibarra",
        "given": "Imanol Arrieta"
      },
      {
        "family": "Kloumann",
        "given": "Isabel"
      },
      {
        "family": "Misra",
        "given": "Ishan"
      },
      {
        "family": "Evtimov",
        "given": "Ivan"
      },
      {
        "family": "Zhang",
        "given": "Jack"
      },
      {
        "family": "Copet",
        "given": "Jade"
      },
      {
        "family": "Lee",
        "given": "Jaewon"
      },
      {
        "family": "Geffert",
        "given": "Jan"
      },
      {
        "family": "Vranes",
        "given": "Jana"
      },
      {
        "family": "Park",
        "given": "Jason"
      },
      {
        "family": "Mahadeokar",
        "given": "Jay"
      },
      {
        "family": "Shah",
        "given": "Jeet"
      },
      {
        "family": "van der Linde",
        "given": "Jelmer"
      },
      {
        "family": "Billock",
        "given": "Jennifer"
      },
      {
        "family": "Hong",
        "given": "Jenny"
      },
      {
        "family": "Lee",
        "given": "Jenya"
      },
      {
        "family": "Fu",
        "given": "Jeremy"
      },
      {
        "family": "Chi",
        "given": "Jianfeng"
      },
      {
        "family": "Huang",
        "given": "Jianyu"
      },
      {
        "family": "Liu",
        "given": "Jiawen"
      },
      {
        "family": "Wang",
        "given": "Jie"
      },
      {
        "family": "Yu",
        "given": "Jiecao"
      },
      {
        "family": "Bitton",
        "given": "Joanna"
      },
      {
        "family": "Spisak",
        "given": "Joe"
      },
      {
        "family": "Park",
        "given": "Jongsoo"
      },
      {
        "family": "Rocca",
        "given": "Joseph"
      },
      {
        "family": "Johnstun",
        "given": "Joshua"
      },
      {
        "family": "Saxe",
        "given": "Joshua"
      },
      {
        "family": "Jia",
        "given": "Junteng"
      },
      {
        "family": "Alwala",
        "given": "Kalyan Vasuden"
      },
      {
        "family": "Prasad",
        "given": "Karthik"
      },
      {
        "family": "Upasani",
        "given": "Kartikeya"
      },
      {
        "family": "Plawiak",
        "given": "Kate"
      },
      {
        "family": "Li",
        "given": "Ke"
      },
      {
        "family": "Heafield",
        "given": "Kenneth"
      },
      {
        "family": "Stone",
        "given": "Kevin"
      },
      {
        "family": "El-Arini",
        "given": "Khalid"
      },
      {
        "family": "Iyer",
        "given": "Krithika"
      },
      {
        "family": "Malik",
        "given": "Kshitiz"
      },
      {
        "family": "Chiu",
        "given": "Kuenley"
      },
      {
        "family": "Bhalla",
        "given": "Kunal"
      },
      {
        "family": "Lakhotia",
        "given": "Kushal"
      },
      {
        "family": "Rantala-Yeary",
        "given": "Lauren"
      },
      {
        "family": "van der Maaten",
        "given": "Laurens"
      },
      {
        "family": "Chen",
        "given": "Lawrence"
      },
      {
        "family": "Tan",
        "given": "Liang"
      },
      {
        "family": "Jenkins",
        "given": "Liz"
      },
      {
        "family": "Martin",
        "given": "Louis"
      },
      {
        "family": "Madaan",
        "given": "Lovish"
      },
      {
        "family": "Malo",
        "given": "Lubo"
      },
      {
        "family": "Blecher",
        "given": "Lukas"
      },
      {
        "family": "Landzaat",
        "given": "Lukas"
      },
      {
        "family": "de Oliveira",
        "given": "Luke"
      },
      {
        "family": "Muzzi",
        "given": "Madeline"
      },
      {
        "family": "Pasupuleti",
        "given": "Mahesh"
      },
      {
        "family": "Singh",
        "given": "Mannat"
      },
      {
        "family": "Paluri",
        "given": "Manohar"
      },
      {
        "family": "Kardas",
        "given": "Marcin"
      },
      {
        "family": "Tsimpoukelli",
        "given": "Maria"
      },
      {
        "family": "Oldham",
        "given": "Mathew"
      },
      {
        "family": "Rita",
        "given": "Mathieu"
      },
      {
        "family": "Pavlova",
        "given": "Maya"
      },
      {
        "family": "Kambadur",
        "given": "Melanie"
      },
      {
        "family": "Lewis",
        "given": "Mike"
      },
      {
        "family": "Si",
        "given": "Min"
      },
      {
        "family": "Singh",
        "given": "Mitesh Kumar"
      },
      {
        "family": "Hassan",
        "given": "Mona"
      },
      {
        "family": "Goyal",
        "given": "Naman"
      },
      {
        "family": "Torabi",
        "given": "Narjes"
      },
      {
        "family": "Bashlykov",
        "given": "Nikolay"
      },
      {
        "family": "Bogoychev",
        "given": "Nikolay"
      },
      {
        "family": "Chatterji",
        "given": "Niladri"
      },
      {
        "family": "Zhang",
        "given": "Ning"
      },
      {
        "family": "Duchenne",
        "given": "Olivier"
      },
      {
        "family": "Çelebi",
        "given": "Onur"
      },
      {
        "family": "Alrassy",
        "given": "Patrick"
      },
      {
        "family": "Zhang",
        "given": "Pengchuan"
      },
      {
        "family": "Li",
        "given": "Pengwei"
      },
      {
        "family": "Vasic",
        "given": "Petar"
      },
      {
        "family": "Weng",
        "given": "Peter"
      },
      {
        "family": "Bhargava",
        "given": "Prajjwal"
      },
      {
        "family": "Dubal",
        "given": "Pratik"
      },
      {
        "family": "Krishnan",
        "given": "Praveen"
      },
      {
        "family": "Koura",
        "given": "Punit Singh"
      },
      {
        "family": "Xu",
        "given": "Puxin"
      },
      {
        "family": "He",
        "given": "Qing"
      },
      {
        "family": "Dong",
        "given": "Qingxiao"
      },
      {
        "family": "Srinivasan",
        "given": "Ragavan"
      },
      {
        "family": "Ganapathy",
        "given": "Raj"
      },
      {
        "family": "Calderer",
        "given": "Ramon"
      },
      {
        "family": "Cabral",
        "given": "Ricardo Silveira"
      },
      {
        "family": "Stojnic",
        "given": "Robert"
      },
      {
        "family": "Raileanu",
        "given": "Roberta"
      },
      {
        "family": "Maheswari",
        "given": "Rohan"
      },
      {
        "family": "Girdhar",
        "given": "Rohit"
      },
      {
        "family": "Patel",
        "given": "Rohit"
      },
      {
        "family": "Sauvestre",
        "given": "Romain"
      },
      {
        "family": "Polidoro",
        "given": "Ronnie"
      },
      {
        "family": "Sumbaly",
        "given": "Roshan"
      },
      {
        "family": "Taylor",
        "given": "Ross"
      },
      {
        "family": "Silva",
        "given": "Ruan"
      },
      {
        "family": "Hou",
        "given": "Rui"
      },
      {
        "family": "Wang",
        "given": "Rui"
      },
      {
        "family": "Hosseini",
        "given": "Saghar"
      },
      {
        "family": "Chennabasappa",
        "given": "Sahana"
      },
      {
        "family": "Singh",
        "given": "Sanjay"
      },
      {
        "family": "Bell",
        "given": "Sean"
      },
      {
        "family": "Kim",
        "given": "Seohyun Sonia"
      },
      {
        "family": "Edunov",
        "given": "Sergey"
      },
      {
        "family": "Nie",
        "given": "Shaoliang"
      },
      {
        "family": "Narang",
        "given": "Sharan"
      },
      {
        "family": "Raparthy",
        "given": "Sharath"
      },
      {
        "family": "Shen",
        "given": "Sheng"
      },
      {
        "family": "Wan",
        "given": "Shengye"
      },
      {
        "family": "Bhosale",
        "given": "Shruti"
      },
      {
        "family": "Zhang",
        "given": "Shun"
      },
      {
        "family": "Vandenhende",
        "given": "Simon"
      },
      {
        "family": "Batra",
        "given": "Soumya"
      },
      {
        "family": "Whitman",
        "given": "Spencer"
      },
      {
        "family": "Sootla",
        "given": "Sten"
      },
      {
        "family": "Collot",
        "given": "Stephane"
      },
      {
        "family": "Gururangan",
        "given": "Suchin"
      },
      {
        "family": "Borodinsky",
        "given": "Sydney"
      },
      {
        "family": "Herman",
        "given": "Tamar"
      },
      {
        "family": "Fowler",
        "given": "Tara"
      },
      {
        "family": "Sheasha",
        "given": "Tarek"
      },
      {
        "family": "Georgiou",
        "given": "Thomas"
      },
      {
        "family": "Scialom",
        "given": "Thomas"
      },
      {
        "family": "Speckbacher",
        "given": "Tobias"
      },
      {
        "family": "Mihaylov",
        "given": "Todor"
      },
      {
        "family": "Xiao",
        "given": "Tong"
      },
      {
        "family": "Karn",
        "given": "Ujjwal"
      },
      {
        "family": "Goswami",
        "given": "Vedanuj"
      },
      {
        "family": "Gupta",
        "given": "Vibhor"
      },
      {
        "family": "Ramanathan",
        "given": "Vignesh"
      },
      {
        "family": "Kerkez",
        "given": "Viktor"
      },
      {
        "family": "Gonguet",
        "given": "Vincent"
      },
      {
        "family": "Do",
        "given": "Virginie"
      },
      {
        "family": "Vogeti",
        "given": "Vish"
      },
      {
        "family": "Albiero",
        "given": "Vítor"
      },
      {
        "family": "Petrovic",
        "given": "Vladan"
      },
      {
        "family": "Chu",
        "given": "Weiwei"
      },
      {
        "family": "Xiong",
        "given": "Wenhan"
      },
      {
        "family": "Fu",
        "given": "Wenyin"
      },
      {
        "family": "Meers",
        "given": "Whitney"
      },
      {
        "family": "Martinet",
        "given": "Xavier"
      },
      {
        "family": "Wang",
        "given": "Xiaodong"
      },
      {
        "family": "Wang",
        "given": "Xiaofang"
      },
      {
        "family": "Tan",
        "given": "Xiaoqing Ellen"
      },
      {
        "family": "Xia",
        "given": "Xide"
      },
      {
        "family": "Xie",
        "given": "Xinfeng"
      },
      {
        "family": "Jia",
        "given": "Xuchao"
      },
      {
        "family": "Wang",
        "given": "Xuewei"
      },
      {
        "family": "Goldschlag",
        "given": "Yaelle"
      },
      {
        "family": "Gaur",
        "given": "Yashesh"
      },
      {
        "family": "Babaei",
        "given": "Yasmine"
      },
      {
        "family": "Wen",
        "given": "Yi"
      },
      {
        "family": "Song",
        "given": "Yiwen"
      },
      {
        "family": "Zhang",
        "given": "Yuchen"
      },
      {
        "family": "Li",
        "given": "Yue"
      },
      {
        "family": "Mao",
        "given": "Yuning"
      },
      {
        "family": "Coudert",
        "given": "Zacharie Delpierre"
      },
      {
        "family": "Yan",
        "given": "Zheng"
      },
      {
        "family": "Chen",
        "given": "Zhengxing"
      },
      {
        "family": "Papakipos",
        "given": "Zoe"
      },
      {
        "family": "Singh",
        "given": "Aaditya"
      },
      {
        "family": "Srivastava",
        "given": "Aayushi"
      },
      {
        "family": "Jain",
        "given": "Abha"
      },
      {
        "family": "Kelsey",
        "given": "Adam"
      },
      {
        "family": "Shajnfeld",
        "given": "Adam"
      },
      {
        "family": "Gangidi",
        "given": "Adithya"
      },
      {
        "family": "Victoria",
        "given": "Adolfo"
      },
      {
        "family": "Goldstand",
        "given": "Ahuva"
      },
      {
        "family": "Menon",
        "given": "Ajay"
      },
      {
        "family": "Sharma",
        "given": "Ajay"
      },
      {
        "family": "Boesenberg",
        "given": "Alex"
      },
      {
        "family": "Baevski",
        "given": "Alexei"
      },
      {
        "family": "Feinstein",
        "given": "Allie"
      },
      {
        "family": "Kallet",
        "given": "Amanda"
      },
      {
        "family": "Sangani",
        "given": "Amit"
      },
      {
        "family": "Teo",
        "given": "Amos"
      },
      {
        "family": "Yunus",
        "given": "Anam"
      },
      {
        "family": "Lupu",
        "given": "Andrei"
      },
      {
        "family": "Alvarado",
        "given": "Andres"
      },
      {
        "family": "Caples",
        "given": "Andrew"
      },
      {
        "family": "Gu",
        "given": "Andrew"
      },
      {
        "family": "Ho",
        "given": "Andrew"
      },
      {
        "family": "Poulton",
        "given": "Andrew"
      },
      {
        "family": "Ryan",
        "given": "Andrew"
      },
      {
        "family": "Ramchandani",
        "given": "Ankit"
      },
      {
        "family": "Dong",
        "given": "Annie"
      },
      {
        "family": "Franco",
        "given": "Annie"
      },
      {
        "family": "Goyal",
        "given": "Anuj"
      },
      {
        "family": "Saraf",
        "given": "Aparajita"
      },
      {
        "family": "Chowdhury",
        "given": "Arkabandhu"
      },
      {
        "family": "Gabriel",
        "given": "Ashley"
      },
      {
        "family": "Bharambe",
        "given": "Ashwin"
      },
      {
        "family": "Eisenman",
        "given": "Assaf"
      },
      {
        "family": "Yazdan",
        "given": "Azadeh"
      },
      {
        "family": "James",
        "given": "Beau"
      },
      {
        "family": "Maurer",
        "given": "Ben"
      },
      {
        "family": "Leonhardi",
        "given": "Benjamin"
      },
      {
        "family": "Huang",
        "given": "Bernie"
      },
      {
        "family": "Loyd",
        "given": "Beth"
      },
      {
        "family": "De Paola",
        "given": "Beto"
      },
      {
        "family": "Paranjape",
        "given": "Bhargavi"
      },
      {
        "family": "Liu",
        "given": "Bing"
      },
      {
        "family": "Wu",
        "given": "Bo"
      },
      {
        "family": "Ni",
        "given": "Boyu"
      },
      {
        "family": "Hancock",
        "given": "Braden"
      },
      {
        "family": "Wasti",
        "given": "Bram"
      },
      {
        "family": "Spence",
        "given": "Brandon"
      },
      {
        "family": "Stojkovic",
        "given": "Brani"
      },
      {
        "family": "Gamido",
        "given": "Brian"
      },
      {
        "family": "Montalvo",
        "given": "Britt"
      },
      {
        "family": "Parker",
        "given": "Carl"
      },
      {
        "family": "Burton",
        "given": "Carly"
      },
      {
        "family": "Mejia",
        "given": "Catalina"
      },
      {
        "family": "Liu",
        "given": "Ce"
      },
      {
        "family": "Wang",
        "given": "Changhan"
      },
      {
        "family": "Kim",
        "given": "Changkyu"
      },
      {
        "family": "Zhou",
        "given": "Chao"
      },
      {
        "family": "Hu",
        "given": "Chester"
      },
      {
        "family": "Chu",
        "given": "Ching-Hsiang"
      },
      {
        "family": "Cai",
        "given": "Chris"
      },
      {
        "family": "Tindal",
        "given": "Chris"
      },
      {
        "family": "Feichtenhofer",
        "given": "Christoph"
      },
      {
        "family": "Gao",
        "given": "Cynthia"
      },
      {
        "family": "Civin",
        "given": "Damon"
      },
      {
        "family": "Beaty",
        "given": "Dana"
      },
      {
        "family": "Kreymer",
        "given": "Daniel"
      },
      {
        "family": "Li",
        "given": "Daniel"
      },
      {
        "family": "Adkins",
        "given": "David"
      },
      {
        "family": "Xu",
        "given": "David"
      },
      {
        "family": "Testuggine",
        "given": "Davide"
      },
      {
        "family": "David",
        "given": "Delia"
      },
      {
        "family": "Parikh",
        "given": "Devi"
      },
      {
        "family": "Liskovich",
        "given": "Diana"
      },
      {
        "family": "Foss",
        "given": "Didem"
      },
      {
        "family": "Wang",
        "given": "Dingkang"
      },
      {
        "family": "Le",
        "given": "Duc"
      },
      {
        "family": "Holland",
        "given": "Dustin"
      },
      {
        "family": "Dowling",
        "given": "Edward"
      },
      {
        "family": "Jamil",
        "given": "Eissa"
      },
      {
        "family": "Montgomery",
        "given": "Elaine"
      },
      {
        "family": "Presani",
        "given": "Eleonora"
      },
      {
        "family": "Hahn",
        "given": "Emily"
      },
      {
        "family": "Wood",
        "given": "Emily"
      },
      {
        "family": "Le",
        "given": "Eric-Tuan"
      },
      {
        "family": "Brinkman",
        "given": "Erik"
      },
      {
        "family": "Arcaute",
        "given": "Esteban"
      },
      {
        "family": "Dunbar",
        "given": "Evan"
      },
      {
        "family": "Smothers",
        "given": "Evan"
      },
      {
        "family": "Sun",
        "given": "Fei"
      },
      {
        "family": "Kreuk",
        "given": "Felix"
      },
      {
        "family": "Tian",
        "given": "Feng"
      },
      {
        "family": "Kokkinos",
        "given": "Filippos"
      },
      {
        "family": "Ozgenel",
        "given": "Firat"
      },
      {
        "family": "Caggioni",
        "given": "Francesco"
      },
      {
        "family": "Kanayet",
        "given": "Frank"
      },
      {
        "family": "Seide",
        "given": "Frank"
      },
      {
        "family": "Florez",
        "given": "Gabriela Medina"
      },
      {
        "family": "Schwarz",
        "given": "Gabriella"
      },
      {
        "family": "Badeer",
        "given": "Gada"
      },
      {
        "family": "Swee",
        "given": "Georgia"
      },
      {
        "family": "Halpern",
        "given": "Gil"
      },
      {
        "family": "Herman",
        "given": "Grant"
      },
      {
        "family": "Sizov",
        "given": "Grigory"
      },
      {
        "family": "Guangyi"
      },
      {
        "family": "Zhang"
      },
      {
        "family": "Lakshminarayanan",
        "given": "Guna"
      },
      {
        "family": "Inan",
        "given": "Hakan"
      },
      {
        "family": "Shojanazeri",
        "given": "Hamid"
      },
      {
        "family": "Zou",
        "given": "Han"
      },
      {
        "family": "Wang",
        "given": "Hannah"
      },
      {
        "family": "Zha",
        "given": "Hanwen"
      },
      {
        "family": "Habeeb",
        "given": "Haroun"
      },
      {
        "family": "Rudolph",
        "given": "Harrison"
      },
      {
        "family": "Suk",
        "given": "Helen"
      },
      {
        "family": "Aspegren",
        "given": "Henry"
      },
      {
        "family": "Goldman",
        "given": "Hunter"
      },
      {
        "family": "Zhan",
        "given": "Hongyuan"
      },
      {
        "family": "Damlaj",
        "given": "Ibrahim"
      },
      {
        "family": "Molybog",
        "given": "Igor"
      },
      {
        "family": "Tufanov",
        "given": "Igor"
      },
      {
        "family": "Leontiadis",
        "given": "Ilias"
      },
      {
        "family": "Veliche",
        "given": "Irina-Elena"
      },
      {
        "family": "Gat",
        "given": "Itai"
      },
      {
        "family": "Weissman",
        "given": "Jake"
      },
      {
        "family": "Geboski",
        "given": "James"
      },
      {
        "family": "Kohli",
        "given": "James"
      },
      {
        "family": "Lam",
        "given": "Janice"
      },
      {
        "family": "Asher",
        "given": "Japhet"
      },
      {
        "family": "Gaya",
        "given": "Jean-Baptiste"
      },
      {
        "family": "Marcus",
        "given": "Jeff"
      },
      {
        "family": "Tang",
        "given": "Jeff"
      },
      {
        "family": "Chan",
        "given": "Jennifer"
      },
      {
        "family": "Zhen",
        "given": "Jenny"
      },
      {
        "family": "Reizenstein",
        "given": "Jeremy"
      },
      {
        "family": "Teboul",
        "given": "Jeremy"
      },
      {
        "family": "Zhong",
        "given": "Jessica"
      },
      {
        "family": "Jin",
        "given": "Jian"
      },
      {
        "family": "Yang",
        "given": "Jingyi"
      },
      {
        "family": "Cummings",
        "given": "Joe"
      },
      {
        "family": "Carvill",
        "given": "Jon"
      },
      {
        "family": "Shepard",
        "given": "Jon"
      },
      {
        "family": "McPhie",
        "given": "Jonathan"
      },
      {
        "family": "Torres",
        "given": "Jonathan"
      },
      {
        "family": "Ginsburg",
        "given": "Josh"
      },
      {
        "family": "Wang",
        "given": "Junjie"
      },
      {
        "family": "Wu",
        "given": "Kai"
      },
      {
        "family": "U",
        "given": "Kam Hou"
      },
      {
        "family": "Saxena",
        "given": "Karan"
      },
      {
        "family": "Khandelwal",
        "given": "Kartikay"
      },
      {
        "family": "Zand",
        "given": "Katayoun"
      },
      {
        "family": "Matosich",
        "given": "Kathy"
      },
      {
        "family": "Veeraraghavan",
        "given": "Kaushik"
      },
      {
        "family": "Michelena",
        "given": "Kelly"
      },
      {
        "family": "Li",
        "given": "Keqian"
      },
      {
        "family": "Jagadeesh",
        "given": "Kiran"
      },
      {
        "family": "Huang",
        "given": "Kun"
      },
      {
        "family": "Chawla",
        "given": "Kunal"
      },
      {
        "family": "Huang",
        "given": "Kyle"
      },
      {
        "family": "Chen",
        "given": "Lailin"
      },
      {
        "family": "Garg",
        "given": "Lakshya"
      },
      {
        "family": "A",
        "given": "Lavender"
      },
      {
        "family": "Silva",
        "given": "Leandro"
      },
      {
        "family": "Bell",
        "given": "Lee"
      },
      {
        "family": "Zhang",
        "given": "Lei"
      },
      {
        "family": "Guo",
        "given": "Liangpeng"
      },
      {
        "family": "Yu",
        "given": "Licheng"
      },
      {
        "family": "Moshkovich",
        "given": "Liron"
      },
      {
        "family": "Wehrstedt",
        "given": "Luca"
      },
      {
        "family": "Khabsa",
        "given": "Madian"
      },
      {
        "family": "Avalani",
        "given": "Manav"
      },
      {
        "family": "Bhatt",
        "given": "Manish"
      },
      {
        "family": "Mankus",
        "given": "Martynas"
      },
      {
        "family": "Hasson",
        "given": "Matan"
      },
      {
        "family": "Lennie",
        "given": "Matthew"
      },
      {
        "family": "Reso",
        "given": "Matthias"
      },
      {
        "family": "Groshev",
        "given": "Maxim"
      },
      {
        "family": "Naumov",
        "given": "Maxim"
      },
      {
        "family": "Lathi",
        "given": "Maya"
      },
      {
        "family": "Keneally",
        "given": "Meghan"
      },
      {
        "family": "Liu",
        "given": "Miao"
      },
      {
        "family": "Seltzer",
        "given": "Michael L."
      },
      {
        "family": "Valko",
        "given": "Michal"
      },
      {
        "family": "Restrepo",
        "given": "Michelle"
      },
      {
        "family": "Patel",
        "given": "Mihir"
      },
      {
        "family": "Vyatskov",
        "given": "Mik"
      },
      {
        "family": "Samvelyan",
        "given": "Mikayel"
      },
      {
        "family": "Clark",
        "given": "Mike"
      },
      {
        "family": "Macey",
        "given": "Mike"
      },
      {
        "family": "Wang",
        "given": "Mike"
      },
      {
        "family": "Hermoso",
        "given": "Miquel Jubert"
      },
      {
        "family": "Metanat",
        "given": "Mo"
      },
      {
        "family": "Rastegari",
        "given": "Mohammad"
      },
      {
        "family": "Bansal",
        "given": "Munish"
      },
      {
        "family": "Santhanam",
        "given": "Nandhini"
      },
      {
        "family": "Parks",
        "given": "Natascha"
      },
      {
        "family": "White",
        "given": "Natasha"
      },
      {
        "family": "Bawa",
        "given": "Navyata"
      },
      {
        "family": "Singhal",
        "given": "Nayan"
      },
      {
        "family": "Egebo",
        "given": "Nick"
      },
      {
        "family": "Usunier",
        "given": "Nicolas"
      },
      {
        "family": "Mehta",
        "given": "Nikhil"
      },
      {
        "family": "Laptev",
        "given": "Nikolay Pavlovich"
      },
      {
        "family": "Dong",
        "given": "Ning"
      },
      {
        "family": "Cheng",
        "given": "Norman"
      },
      {
        "family": "Chernoguz",
        "given": "Oleg"
      },
      {
        "family": "Hart",
        "given": "Olivia"
      },
      {
        "family": "Salpekar",
        "given": "Omkar"
      },
      {
        "family": "Kalinli",
        "given": "Ozlem"
      },
      {
        "family": "Kent",
        "given": "Parkin"
      },
      {
        "family": "Parekh",
        "given": "Parth"
      },
      {
        "family": "Saab",
        "given": "Paul"
      },
      {
        "family": "Balaji",
        "given": "Pavan"
      },
      {
        "family": "Rittner",
        "given": "Pedro"
      },
      {
        "family": "Bontrager",
        "given": "Philip"
      },
      {
        "family": "Roux",
        "given": "Pierre"
      },
      {
        "family": "Dollar",
        "given": "Piotr"
      },
      {
        "family": "Zvyagina",
        "given": "Polina"
      },
      {
        "family": "Ratanchandani",
        "given": "Prashant"
      },
      {
        "family": "Yuvraj",
        "given": "Pritish"
      },
      {
        "family": "Liang",
        "given": "Qian"
      },
      {
        "family": "Alao",
        "given": "Rachad"
      },
      {
        "family": "Rodriguez",
        "given": "Rachel"
      },
      {
        "family": "Ayub",
        "given": "Rafi"
      },
      {
        "family": "Murthy",
        "given": "Raghotham"
      },
      {
        "family": "Nayani",
        "given": "Raghu"
      },
      {
        "family": "Mitra",
        "given": "Rahul"
      },
      {
        "family": "Parthasarathy",
        "given": "Rangaprabhu"
      },
      {
        "family": "Li",
        "given": "Raymond"
      },
      {
        "family": "Hogan",
        "given": "Rebekkah"
      },
      {
        "family": "Battey",
        "given": "Robin"
      },
      {
        "family": "Wang",
        "given": "Rocky"
      },
      {
        "family": "Howes",
        "given": "Russ"
      },
      {
        "family": "Rinott",
        "given": "Ruty"
      },
      {
        "family": "Mehta",
        "given": "Sachin"
      },
      {
        "family": "Siby",
        "given": "Sachin"
      },
      {
        "family": "Bondu",
        "given": "Sai Jayesh"
      },
      {
        "family": "Datta",
        "given": "Samyak"
      },
      {
        "family": "Chugh",
        "given": "Sara"
      },
      {
        "family": "Hunt",
        "given": "Sara"
      },
      {
        "family": "Dhillon",
        "given": "Sargun"
      },
      {
        "family": "Sidorov",
        "given": "Sasha"
      },
      {
        "family": "Pan",
        "given": "Satadru"
      },
      {
        "family": "Mahajan",
        "given": "Saurabh"
      },
      {
        "family": "Verma",
        "given": "Saurabh"
      },
      {
        "family": "Yamamoto",
        "given": "Seiji"
      },
      {
        "family": "Ramaswamy",
        "given": "Sharadh"
      },
      {
        "family": "Lindsay",
        "given": "Shaun"
      },
      {
        "family": "Lindsay",
        "given": "Shaun"
      },
      {
        "family": "Feng",
        "given": "Sheng"
      },
      {
        "family": "Lin",
        "given": "Shenghao"
      },
      {
        "family": "Zha",
        "given": "Shengxin Cindy"
      },
      {
        "family": "Patil",
        "given": "Shishir"
      },
      {
        "family": "Shankar",
        "given": "Shiva"
      },
      {
        "family": "Zhang",
        "given": "Shuqiang"
      },
      {
        "family": "Zhang",
        "given": "Shuqiang"
      },
      {
        "family": "Wang",
        "given": "Sinong"
      },
      {
        "family": "Agarwal",
        "given": "Sneha"
      },
      {
        "family": "Sajuyigbe",
        "given": "Soji"
      },
      {
        "family": "Chintala",
        "given": "Soumith"
      },
      {
        "family": "Max",
        "given": "Stephanie"
      },
      {
        "family": "Chen",
        "given": "Stephen"
      },
      {
        "family": "Kehoe",
        "given": "Steve"
      },
      {
        "family": "Satterfield",
        "given": "Steve"
      },
      {
        "family": "Govindaprasad",
        "given": "Sudarshan"
      },
      {
        "family": "Gupta",
        "given": "Sumit"
      },
      {
        "family": "Deng",
        "given": "Summer"
      },
      {
        "family": "Cho",
        "given": "Sungmin"
      },
      {
        "family": "Virk",
        "given": "Sunny"
      },
      {
        "family": "Subramanian",
        "given": "Suraj"
      },
      {
        "family": "Choudhury",
        "given": "Sy"
      },
      {
        "family": "Goldman",
        "given": "Sydney"
      },
      {
        "family": "Remez",
        "given": "Tal"
      },
      {
        "family": "Glaser",
        "given": "Tamar"
      },
      {
        "family": "Best",
        "given": "Tamara"
      },
      {
        "family": "Koehler",
        "given": "Thilo"
      },
      {
        "family": "Robinson",
        "given": "Thomas"
      },
      {
        "family": "Li",
        "given": "Tianhe"
      },
      {
        "family": "Zhang",
        "given": "Tianjun"
      },
      {
        "family": "Matthews",
        "given": "Tim"
      },
      {
        "family": "Chou",
        "given": "Timothy"
      },
      {
        "family": "Shaked",
        "given": "Tzook"
      },
      {
        "family": "Vontimitta",
        "given": "Varun"
      },
      {
        "family": "Ajayi",
        "given": "Victoria"
      },
      {
        "family": "Montanez",
        "given": "Victoria"
      },
      {
        "family": "Mohan",
        "given": "Vijai"
      },
      {
        "family": "Kumar",
        "given": "Vinay Satish"
      },
      {
        "family": "Mangla",
        "given": "Vishal"
      },
      {
        "family": "Ionescu",
        "given": "Vlad"
      },
      {
        "family": "Poenaru",
        "given": "Vlad"
      },
      {
        "family": "Mihailescu",
        "given": "Vlad Tiberiu"
      },
      {
        "family": "Ivanov",
        "given": "Vladimir"
      },
      {
        "family": "Li",
        "given": "Wei"
      },
      {
        "family": "Wang",
        "given": "Wenchen"
      },
      {
        "family": "Jiang",
        "given": "Wenwen"
      },
      {
        "family": "Bouaziz",
        "given": "Wes"
      },
      {
        "family": "Constable",
        "given": "Will"
      },
      {
        "family": "Tang",
        "given": "Xiaocheng"
      },
      {
        "family": "Wu",
        "given": "Xiaojian"
      },
      {
        "family": "Wang",
        "given": "Xiaolan"
      },
      {
        "family": "Wu",
        "given": "Xilun"
      },
      {
        "family": "Gao",
        "given": "Xinbo"
      },
      {
        "family": "Kleinman",
        "given": "Yaniv"
      },
      {
        "family": "Chen",
        "given": "Yanjun"
      },
      {
        "family": "Hu",
        "given": "Ye"
      },
      {
        "family": "Jia",
        "given": "Ye"
      },
      {
        "family": "Qi",
        "given": "Ye"
      },
      {
        "family": "Li",
        "given": "Yenda"
      },
      {
        "family": "Zhang",
        "given": "Yilin"
      },
      {
        "family": "Zhang",
        "given": "Ying"
      },
      {
        "family": "Adi",
        "given": "Yossi"
      },
      {
        "family": "Nam",
        "given": "Youngjin"
      },
      {
        "family": "Yu"
      },
      {
        "literal": "Wang"
      },
      {
        "family": "Zhao",
        "given": "Yu"
      },
      {
        "family": "Hao",
        "given": "Yuchen"
      },
      {
        "family": "Qian",
        "given": "Yundi"
      },
      {
        "family": "Li",
        "given": "Yunlu"
      },
      {
        "family": "He",
        "given": "Yuzi"
      },
      {
        "family": "Rait",
        "given": "Zach"
      },
      {
        "family": "DeVito",
        "given": "Zachary"
      },
      {
        "family": "Rosnbrick",
        "given": "Zef"
      },
      {
        "family": "Wen",
        "given": "Zhaoduo"
      },
      {
        "family": "Yang",
        "given": "Zhenyu"
      },
      {
        "family": "Zhao",
        "given": "Zhiwei"
      },
      {
        "family": "Ma",
        "given": "Zhiyu"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "abstract": "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.",
    "DOI": "10.48550/arxiv.2407.21783",
    "publisher": "arXiv",
    "title": "The Llama 3 Herd of Models",
    "URL": "https://doi.org/ndw6",
    "version": "3",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2407.21783"
  },
  {
    "type": "article",
    "id": "XpHq6HEw",
    "categories": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "FOS: Computer and information sciences",
      "FOS: Computer and information sciences"
    ],
    "author": [
      {
        "family": "Zhong",
        "given": "Ruiqi"
      },
      {
        "family": "Wang",
        "given": "Heng"
      },
      {
        "family": "Klein",
        "given": "Dan"
      },
      {
        "family": "Steinhardt",
        "given": "Jacob"
      }
    ],
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "abstract": "To make sense of massive data, we often fit simplified models and then interpret the parameters; for example, we cluster the text embeddings and then interpret the mean parameters of each cluster. However, these parameters are often high-dimensional and hard to interpret. To make model parameters directly interpretable, we introduce a family of statistical models -- including clustering, time series, and classification models -- parameterized by natural language predicates. For example, a cluster of text about COVID could be parameterized by the predicate \"discusses COVID\". To learn these statistical models effectively, we develop a model-agnostic algorithm that optimizes continuous relaxations of predicate parameters with gradient descent and discretizes them by prompting language models (LMs). Finally, we apply our framework to a wide range of problems: taxonomizing user chat dialogues, characterizing how they evolve across time, finding categories where one language model is better than the other, clustering math problems based on subareas, and explaining visual features in memorable images. Our framework is highly versatile, applicable to both textual and visual domains, can be easily steered to focus on specific properties (e.g. subareas), and explains sophisticated concepts that classical methods (e.g. n-gram analysis) struggle to produce.",
    "DOI": "10.48550/arxiv.2409.08466",
    "publisher": "arXiv",
    "title": "Explaining Datasets in Words: Statistical Models with Natural Language Parameters",
    "URL": "https://doi.org/g9t22k",
    "version": "2",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.48550/arxiv.2409.08466"
  },
  {
    "publisher": "School of Statistics, Renmin University of China",
    "abstract": "<jats:p>Studying migration patterns driven by extreme environmental events is crucial for building a sustainable society and stable economy. Motivated by a real dataset about human migrations, this paper develops a transformed varying coefficient model for origin and destination (OD) regression to elucidate the complex associations of migration patterns with spatio-temporal dependencies and socioeconomic factors. Existing studies often overlook the dynamic effects of these factors in OD regression. Furthermore, with the increasing ease of collecting OD data, the scale of current OD regression data is typically large, necessitating the development of methods for efficiently fitting large-scale migration data. We address the challenge by proposing a new Bayesian interpretation for the proposed OD models, leveraging sufficient statistics for efficient big data computation. Our method, inspired by migration studies, promises broad applicability across various fields, contributing to refined statistical analysis techniques. Extensive numerical studies are provided, and insights from real data analysis are shared.</jats:p>",
    "DOI": "10.6339/25-jds1181",
    "type": "article-journal",
    "page": "353-369",
    "source": "Crossref",
    "title": "Exact Inference for Transformed Large-Scale Varying Coefficient Models with Applications",
    "author": [
      {
        "given": "Tianyu",
        "family": "Chen"
      },
      {
        "given": "Robert",
        "family": "Habans"
      },
      {
        "given": "Thomas",
        "family": "Douthat"
      },
      {
        "given": "Jenna",
        "family": "Losh"
      },
      {
        "given": "Lida",
        "family": "Chalangar Jalili Dehkharghani"
      },
      {
        "given": "Li-Hsiang",
        "family": "Lin"
      }
    ],
    "container-title": "Journal of Data Science",
    "language": "en",
    "issued": {
      "date-parts": [
        [
          2025,
          1,
          1
        ]
      ]
    },
    "URL": "https://doi.org/g9t2rs",
    "id": "14C9q1ybi",
    "note": "This CSL Item was generated by Manubot v0.6.1 from its persistent identifier (standard_id).\nstandard_id: doi:10.6339/25-jds1181"
  },
  {
    "id": "TPky1hwV",
    "type": "manuscript",
    "author": [
      {
        "family": "Dong",
        "given": "Qingxiu"
      },
      {
        "family": "Li",
        "given": "Lei"
      },
      {
        "family": "Dai",
        "given": "Damai"
      },
      {
        "family": "Zheng",
        "given": "Ce"
      },
      {
        "family": "Wu",
        "given": "Zhiyong"
      },
      {
        "family": "Chang",
        "given": "Baobao"
      },
      {
        "family": "Sun",
        "given": "Xu"
      },
      {
        "family": "Xu",
        "given": "Jingjing"
      },
      {
        "family": "Huang",
        "given": "Fei"
      },
      {
        "family": "Li",
        "given": "Xin"
      }
    ],
    "title": "A Survey for In-context Learning",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: dong2022survey"
  },
  {
    "id": "Vl20CyW4",
    "type": "manuscript",
    "author": [
      {
        "family": "Doshi-Velez",
        "given": "Finale"
      },
      {
        "family": "Kim",
        "given": "Been"
      }
    ],
    "title": "Towards a Rigorous Science of Interpretable Machine Learning",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: doshi2017towards"
  },
  {
    "id": "YcdobJB",
    "type": "manuscript",
    "author": [
      {
        "family": "Englert",
        "given": "Jacob"
      },
      {
        "family": "Chang",
        "given": "Howard"
      }
    ],
    "title": "Spatially Varying Coefficient Models for Estimating Heterogeneous Mixture Effects",
    "archive": "arXiv",
    "note": "stat.AP\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: englert2025spatially"
  },
  {
    "id": "eIFyeYdp",
    "type": "article-journal",
    "author": [
      {
        "family": "Fan",
        "given": "Xinyan"
      },
      {
        "family": "Fang",
        "given": "Kuangnan"
      },
      {
        "family": "Lan",
        "given": "Wei"
      },
      {
        "family": "Tsai",
        "given": "Chih-Ling"
      }
    ],
    "title": "Network Varying Coefficient Model",
    "container-title": "Journal of the American Statistical Association",
    "DOI": "10.1080/01621459.2025.2470481",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: fan2025network"
  },
  {
    "id": "qKQnj4go",
    "type": "paper-conference",
    "author": [
      {
        "family": "Finn",
        "given": "Chelsea"
      },
      {
        "family": "Abbeel",
        "given": "Pieter"
      },
      {
        "family": "Levine",
        "given": "Sergey"
      }
    ],
    "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
    "container-title": "Proceedings of the 34th International Conference on Machine Learning",
    "page": "1126--1135",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: finn2017model"
  },
  {
    "id": "nJe4KvW1",
    "type": "article-journal",
    "author": [
      {
        "family": "Hastie",
        "given": "Trevor"
      },
      {
        "family": "Tibshirani",
        "given": "Robert"
      }
    ],
    "title": "Varying-coefficient models",
    "container-title": "Journal of the Royal Statistical Society: Series B (Methodological)",
    "volume": "55",
    "issue": "4",
    "page": "757--796",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: hastie1993varying"
  },
  {
    "id": "17ZQvSfwG",
    "type": "article-journal",
    "author": [
      {
        "family": "Hospedales",
        "given": "Timothy"
      },
      {
        "family": "Antoniou",
        "given": "Antreas"
      },
      {
        "family": "Micaelli",
        "given": "Paul"
      },
      {
        "family": "Storkey",
        "given": "Amos"
      }
    ],
    "title": "Meta-Learning in Neural Networks: A Survey",
    "container-title": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "volume": "44",
    "issue": "9",
    "page": "5149--5169",
    "DOI": "10.1109/TPAMI.2021.3079209",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: hospedales2021meta"
  },
  {
    "id": "OWMnVMab",
    "type": "article-journal",
    "author": [
      {
        "family": "Hu",
        "given": "Yiqing"
      },
      {
        "family": "Zhao",
        "given": "Qingyuan"
      }
    ],
    "title": "Varying-Coefficient Panel Models with Spatial Dependence",
    "container-title": "Journal of Econometrics",
    "volume": "241",
    "issue": "1",
    "page": "105883",
    "DOI": "10.1016/j.jeconom.2024.105883",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: hu2024varying"
  },
  {
    "id": "1BRT5VuZM",
    "type": "manuscript",
    "author": [
      {
        "family": "Kingma",
        "given": "Diederik P."
      },
      {
        "family": "Welling",
        "given": "Max"
      }
    ],
    "title": "Auto-Encoding Variational Bayes",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: kingma2013auto"
  },
  {
    "id": "nHWat6vD",
    "type": "manuscript",
    "author": [
      {
        "family": "Kingma",
        "given": "Diederik P."
      },
      {
        "family": "Ba",
        "given": "Jimmy"
      }
    ],
    "title": "Adam: A method for stochastic optimization",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: kingma2014adam"
  },
  {
    "id": "lGpaLCJV",
    "type": "article-journal",
    "author": [
      {
        "family": "Lei",
        "given": "Yaguo"
      },
      {
        "family": "Li",
        "given": "Naipeng"
      },
      {
        "family": "Gontarz",
        "given": "Stanislaw"
      },
      {
        "family": "Lin",
        "given": "Jing"
      },
      {
        "family": "Radkowski",
        "given": "Slawomir"
      },
      {
        "family": "Dybala",
        "given": "Jacek"
      }
    ],
    "title": "A Model-based method for remaining useful life prediction of machinery",
    "container-title": "IEEE Transactions on Reliability",
    "volume": "65",
    "issue": "3",
    "page": "1314--1326",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: lei2018machinery"
  },
  {
    "id": "5WaW1b3E",
    "type": "article-journal",
    "author": [
      {
        "family": "Li",
        "given": "Ting"
      },
      {
        "family": "Yu",
        "given": "Yang"
      },
      {
        "family": "Wang",
        "given": "Xiao"
      },
      {
        "family": "Marron",
        "given": "J.S."
      },
      {
        "family": "Zhu",
        "given": "Hongtu"
      }
    ],
    "title": "Semi-nonparametric Varying Coefficients Models for Imaging Genetics",
    "container-title": "Statistica Sinica",
    "note": "To appear\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: li2024semi",
    "DOI": "10.5705/ss.202024.0118"
  },
  {
    "id": "40yMf8Is",
    "type": "article-journal",
    "author": [
      {
        "family": "Linardatos",
        "given": "Pantelis"
      },
      {
        "family": "Papastefanopoulos",
        "given": "Vasilis"
      },
      {
        "family": "Kotsiantis",
        "given": "Sotiris"
      }
    ],
    "title": "Explainable AI: A Review of Machine Learning Interpretability Methods",
    "container-title": "Entropy",
    "volume": "23",
    "issue": "1",
    "page": "18",
    "DOI": "10.3390/e23010018",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: linardatos2020explainable"
  },
  {
    "id": "2tgTw2mh",
    "type": "paper-conference",
    "author": [
      {
        "family": "Locatello",
        "given": "Francesco"
      },
      {
        "family": "Bauer",
        "given": "Stefan"
      },
      {
        "family": "Lucic",
        "given": "Mario"
      },
      {
        "family": "Gelly",
        "given": "Sylvain"
      },
      {
        "family": "Schölkopf",
        "given": "Bernhard"
      },
      {
        "family": "Bachem",
        "given": "Olivier"
      }
    ],
    "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
    "container-title": "International Conference on Machine Learning",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: locatello2019challenging"
  },
  {
    "id": "UiqiqyOG",
    "type": "article-journal",
    "author": [
      {
        "family": "Luo",
        "given": "Chongliang"
      },
      {
        "family": "Du",
        "given": "Yihong"
      },
      {
        "family": "Zhao",
        "given": "Peng"
      }
    ],
    "title": "Urban Economic Modeling with Spatially Varying Coefficients",
    "container-title": "Regional Science and Urban Economics",
    "volume": "99",
    "page": "104009",
    "DOI": "10.1016/j.regsciurbeco.2024.104009",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: luo2024urban"
  },
  {
    "id": "ZYb8Bxk0",
    "type": "paper-conference",
    "author": [
      {
        "family": "Min",
        "given": "Sewon"
      },
      {
        "family": "Lyu",
        "given": "Xinxi"
      },
      {
        "family": "Holtzman",
        "given": "Ari"
      },
      {
        "family": "Artetxe",
        "given": "Mikel"
      },
      {
        "family": "Lewis",
        "given": "Mike"
      },
      {
        "family": "Hajishirzi",
        "given": "Hannaneh"
      },
      {
        "family": "Zettlemoyer",
        "given": "Luke"
      }
    ],
    "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    "container-title": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    "page": "11048--11064",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: min2022rethinking"
  },
  {
    "id": "HmeksLbr",
    "type": "article-journal",
    "author": [
      {
        "family": "Murakami",
        "given": "Daisuke"
      },
      {
        "family": "Shirota",
        "given": "Shinichiro"
      },
      {
        "family": "Kajita",
        "given": "Seiji"
      },
      {
        "family": "Kajita",
        "given": "Mami"
      }
    ],
    "title": "Fast Spatio-Temporally Varying Coefficient Modeling With Reluctant Interaction Selection",
    "container-title": "Geographical Analysis",
    "volume": "57",
    "page": "521--539",
    "DOI": "10.1111/gean.70005",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: murakami2025fast"
  },
  {
    "id": "150dVFuGy",
    "type": "manuscript",
    "author": [
      {
        "family": "Olsson",
        "given": "Catherine"
      }
    ],
    "title": "In-context Learning and Induction Heads",
    "note": "and others\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: olsson2022incontext",
    "archive": "arXiv"
  },
  {
    "id": "Zxb6oJ4N",
    "type": "paper-conference",
    "author": [
      {
        "family": "Petroni",
        "given": "Fabio"
      },
      {
        "family": "Rocktäschel",
        "given": "Tim"
      },
      {
        "family": "Riedel",
        "given": "Sebastian"
      },
      {
        "family": "Lewis",
        "given": "Patrick S. H."
      },
      {
        "family": "Bakhtin",
        "given": "Anton"
      },
      {
        "family": "Wu",
        "given": "Yuxiang"
      },
      {
        "family": "Miller",
        "given": "Alexander H."
      }
    ],
    "title": "Language Models as Knowledge Bases?",
    "container-title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    "page": "2463--2473",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: petroni2019language"
  },
  {
    "id": "1AsYpVghl",
    "type": "manuscript",
    "author": [
      {
        "family": "Ruder",
        "given": "Sebastian"
      }
    ],
    "title": "An Overview of Multi-Task Learning in Deep Neural Networks",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: ruder2017overview"
  },
  {
    "id": "f8UfQHob",
    "type": "manuscript",
    "author": [
      {
        "family": "Shi",
        "given": "Yu"
      },
      {
        "family": "Liu",
        "given": "Yang"
      },
      {
        "family": "Yan",
        "given": "Hao"
      }
    ],
    "title": "Graph-Regularized Estimation for Context-Varying Models",
    "archive": "arXiv",
    "note": "stat.ME\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: shi2021graph"
  },
  {
    "id": "PeotCKyQ",
    "type": "article-journal",
    "author": [
      {
        "family": "Tibshirani",
        "given": "Robert"
      }
    ],
    "title": "Regression shrinkage and selection via the lasso",
    "container-title": "Journal of the Royal Statistical Society: Series B (Methodological)",
    "volume": "58",
    "issue": "1",
    "page": "267--288",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: tibshirani1996regression"
  },
  {
    "id": "eqOwOT6q",
    "type": "paper-conference",
    "author": [
      {
        "family": "Vaswani",
        "given": "Ashish"
      },
      {
        "family": "Shazeer",
        "given": "Noam"
      },
      {
        "family": "Parmar",
        "given": "Niki"
      },
      {
        "family": "Uszkoreit",
        "given": "Jakob"
      },
      {
        "family": "Jones",
        "given": "Llion"
      },
      {
        "family": "Gomez",
        "given": "Aidan N."
      },
      {
        "family": "Kaiser",
        "given": "Lukasz"
      },
      {
        "family": "Polosukhin",
        "given": "Illia"
      }
    ],
    "title": "Attention Is All You Need",
    "container-title": "Advances in Neural Information Processing Systems 30",
    "page": "5998--6008",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: vaswani2017attention"
  },
  {
    "id": "1CanAlj65",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ataee Tarzanagh",
        "given": "Davoud"
      },
      {
        "family": "Li",
        "given": "Yingcong"
      },
      {
        "family": "Thrampoulidis",
        "given": "Christos"
      },
      {
        "family": "Oymak",
        "given": "Samet"
      }
    ],
    "title": "Transformers as Support Vector Machines",
    "container-title": "Proceedings of the 40th International Conference on Machine Learning",
    "page": "35017--35037",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: von2023transformers"
  },
  {
    "id": "1A9CGb6kl",
    "type": "paper-conference",
    "author": [
      {
        "family": "Balseiro",
        "given": "Santiago"
      },
      {
        "family": "Golrezaei",
        "given": "Negin"
      },
      {
        "family": "Mahdian",
        "given": "Mohammad"
      },
      {
        "family": "Mirrokni",
        "given": "Vahab"
      },
      {
        "family": "Schneider",
        "given": "Jon"
      }
    ],
    "title": "Contextual Bandits with Cross-Learning",
    "container-title": "Advances in Neural Information Processing Systems",
    "volume": "32",
    "page": "",
    "publisher": "Curran Associates, Inc.",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: wang2018contextual"
  },
  {
    "id": "Do5Pmykz",
    "type": "manuscript",
    "author": [
      {
        "family": "Dzhoha",
        "given": "Andrii"
      },
      {
        "family": "Mironenko",
        "given": "Alisa"
      },
      {
        "family": "Labzin",
        "given": "Evgeny"
      },
      {
        "family": "Vlasov",
        "given": "Vladimir"
      },
      {
        "family": "Versteegh",
        "given": "Maarten"
      },
      {
        "family": "Celikik",
        "given": "Marjan"
      }
    ],
    "title": "Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation",
    "archive": "arXiv",
    "note": "cs.IR\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: wang2019efficiency"
  },
  {
    "id": "VphcPzBL",
    "type": "article-journal",
    "author": [
      {
        "family": "Wang",
        "given": "Yunfei"
      },
      {
        "family": "Sun",
        "given": "Qiang"
      }
    ],
    "title": "Boosted Trees for Varying-Coefficient Models",
    "container-title": "Machine Learning",
    "note": "To appear\nLoaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: wang2025boosted",
    "DOI": "10.1007/s00180-025-01603-8"
  },
  {
    "id": "BXrKAqFG",
    "type": "paper-conference",
    "author": [
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Wang",
        "given": "Xuezhi"
      },
      {
        "family": "Schuurmans",
        "given": "Dale"
      },
      {
        "family": "Bosma",
        "given": "Maarten"
      },
      {
        "family": "Xia",
        "given": "Fei"
      },
      {
        "family": "Chi",
        "given": "Ed"
      },
      {
        "family": "Le",
        "given": "Quoc V."
      },
      {
        "family": "Zhou",
        "given": "Denny"
      }
    ],
    "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
    "container-title": "Advances in Neural Information Processing Systems 35",
    "page": "6021--6035",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: wei2022chain"
  },
  {
    "id": "z62tJ72i",
    "type": "article-journal",
    "author": [
      {
        "family": "Wei",
        "given": "Jason"
      },
      {
        "family": "Tay",
        "given": "Yi"
      },
      {
        "family": "Bommasani",
        "given": "Rishi"
      },
      {
        "family": "Raffel",
        "given": "Colin"
      },
      {
        "family": "Zoph",
        "given": "Barret"
      },
      {
        "family": "Borgeaud",
        "given": "Sebastian"
      },
      {
        "family": "Yogatama",
        "given": "Dani"
      },
      {
        "family": "Bosma",
        "given": "Maarten"
      },
      {
        "family": "Zhou",
        "given": "Denny"
      },
      {
        "family": "Metzler",
        "given": "Donald"
      },
      {
        "family": "Chi",
        "given": "Ed H."
      },
      {
        "family": "Hashimoto",
        "given": "Tatsunori"
      },
      {
        "family": "Vinyals",
        "given": "Oriol"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Dean",
        "given": "Jeff"
      },
      {
        "family": "Fedus",
        "given": "William"
      }
    ],
    "title": "Emergent Abilities of Large Language Models",
    "container-title": "Transactions on Machine Learning Research",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: wei2022emergent"
  },
  {
    "id": "dg3bTKFO",
    "type": "manuscript",
    "author": [
      {
        "family": "Xie",
        "given": "Sang Michael"
      },
      {
        "family": "Raghunathan",
        "given": "Aditi"
      },
      {
        "family": "Liang",
        "given": "Percy"
      },
      {
        "family": "Ma",
        "given": "Tengyu"
      }
    ],
    "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
    "archive": "arXiv",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: xie2021an"
  },
  {
    "id": "6zMua9lq",
    "type": "article-journal",
    "author": [
      {
        "family": "Yuan",
        "given": "Ming"
      },
      {
        "family": "Lin",
        "given": "Yi"
      }
    ],
    "title": "Model selection and estimation in regression with grouped variables",
    "container-title": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
    "volume": "68",
    "issue": "1",
    "page": "49--67",
    "note": "Loaded from an external bibliography file by Manubot.\nsource_bibliography: manual-references.json\nstandard_id: yuan2006model"
  }
]
